[
  {
    "objectID": "assignment/index.html",
    "href": "assignment/index.html",
    "title": "Assignments",
    "section": "",
    "text": "The main goals of this class are to help you design, critique, code, and run rigorous, valid, and feasible evaluations of public sector programs. Each type of assignment in this class is designed to help you achieve one or more of these goals."
  },
  {
    "objectID": "assignment/index.html#weekly-check-in",
    "href": "assignment/index.html#weekly-check-in",
    "title": "Assignments",
    "section": "Weekly check-in",
    "text": "Weekly check-in\nEvery week, after you finish working through the content, I want to hear about what you learned and what questions you still have. Because the content in thsi course is flipped, these questions are crucial for our weekly in-class discussions.\nTo encourage engagement with the course content—and to allow me to collect the class’s questions each week—you’ll need to fill out a short response on iCollege. This should be ≈150 words. That’s fairly short: there are ≈250 words on a typical double-spaced page in Microsoft Word (500 when single-spaced).\nThese check-ins are due by noon on the days we have class. This is so I can look through the responses and start structuring the discussion for the evening’s class.\nYou should answer these two questions each week:\n\nWhat were the three (3) most interesting or exciting things you learned from the session? Why?\nWhat were the three (3) muddiest or unclear things from the session this week? What are you still wondering about?\n\nYou can include more than three interesting or muddiest things, but you must include at least three. There should be six easily identifiable things in each check-in: three exciting things and three questions.\nI will grade these check-ins using a check system:\n\n✔+: (11.5 points (115%) in gradebook) Response shows phenomenal thought and engagement with the course content. I will not assign these often.\n✔: (10 points (100%) in gradebook) Response is thoughtful, well-written, and shows engagement with the course content. This is the expected level of performance.\n✔−: (5 points (50%) in gradebook) Response is hastily composed, too short, and/or only cursorily engages with the course content. This grade signals that you need to improve next time. I will hopefully not assign these often.\n\nNotice that is essentially a pass/fail or completion-based system. I’m not grading your writing ability, I’m not counting the exact number of words you’re writing, and I’m not looking for encyclopedic citations of every single reading to prove that you did indeed read everything. I’m looking for thoughtful engagement, three interesting things, and three questions. That’s all. Do good work and you’ll get a ✓.\nYou will submit these check-ins via iCollege."
  },
  {
    "objectID": "assignment/index.html#problem-sets",
    "href": "assignment/index.html#problem-sets",
    "title": "Assignments",
    "section": "Problem sets",
    "text": "Problem sets\nTo practice writing R code, running inferential models, and thinking about causation, you will complete a series of problem sets.\nYou need to show that you made a good faith effort to work each question. I will not grade these in detail. The problem sets will be graded using a check system:\n\n✔+: (33 points (110%) in gradebook) Assignment is 100% completed. Every question was attempted and answered, and most answers are correct. Document is clean and easy to follow. Work is exceptional. I will not assign these often.\n✔: (30 points (100%) in gradebook) Assignment is 70–99% complete and most answers are correct. This is the expected level of performance.\n✔−: (15 points (50%) in gradebook) Assignment is less than 70% complete and/or most answers are incorrect. This indicates that you need to improve next time. I will hopefully not asisgn these often.\n\nYou may (and should!) work together on the problem sets, but you must turn in your own answers. You cannot work in groups of more than four people, and you must note who participated in the group in your assignment."
  },
  {
    "objectID": "assignment/index.html#evaluation-assignments",
    "href": "assignment/index.html#evaluation-assignments",
    "title": "Assignments",
    "section": "Evaluation assignments",
    "text": "Evaluation assignments\nFor your final project, you will conduct a pre-registered evaluation of a social program using synthetic data. To (1) give you practice with the principles of program evaluation, research design, measurement, and causal diagrams, and (2) help you with the foundation of your final project, you will complete a set of four evaluation-related assignments.\nIdeally these will become major sections of your final project. However, there is no requirement that the programs you use in these assignments must be the same as the final project. If, through these assignments, you discover that your initially chosen program is too simple, too complex, too boring, etc., you can change at any time.\nThese assignments will be graded using a check system:\n\n✔+: (33 points (110%) in gradebook) Assignment is 100% completed. Every question was attempted and answered, and most answers are correct. Document is clean and easy to follow. Work is exceptional. I will not assign these often.\n✔: (30 points (100%) in gradebook) Assignment is 70–99% complete and most answers are correct. This is the expected level of performance.\n✔−: (15 points (50%) in gradebook) Assignment is less than 70% complete and/or most answers are incorrect. This indicates that you need to improve next time. I will hopefully not asisgn these often."
  },
  {
    "objectID": "assignment/index.html#exams",
    "href": "assignment/index.html#exams",
    "title": "Assignments",
    "section": "Exams",
    "text": "Exams\nThere will be two exams covering (1) program evaluation, design, and causation, and (2) the core statistical tools of program evaluation and causal inference.\nYou will take these exams online through iCollege. The exams will have a time limit, but you can use notes and readings and the Google. You must take the exams on your own though, and not talk to anyone about them."
  },
  {
    "objectID": "assignment/index.html#final-project",
    "href": "assignment/index.html#final-project",
    "title": "Assignments",
    "section": "Final project",
    "text": "Final project\nAt the end of the course, you will demonstrate your knowledge of program evaluation and causal inference by completing a final project.\nComplete details for the final project are here.\nThere is no final exam. This project is your final exam."
  },
  {
    "objectID": "content/01-content.html#lecturas",
    "href": "content/01-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas\nR for Data Science"
  },
  {
    "objectID": "content/02-content.html#lecturas",
    "href": "content/02-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas\nR for Data Science"
  },
  {
    "objectID": "content/03-content.html#lecturas",
    "href": "content/03-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas\nR for Data Science"
  },
  {
    "objectID": "content/04-content.html#lecturas",
    "href": "content/04-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas\nR for Data Science"
  },
  {
    "objectID": "content/05-content.html#lecturas",
    "href": "content/05-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas\nR for Data Science"
  },
  {
    "objectID": "content/06-content.html#lecturas",
    "href": "content/06-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas\nR for Data Science"
  },
  {
    "objectID": "content/07-content.html#lecturas",
    "href": "content/07-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas\nBrown (2015)The Common Factor Model and Exploratory Factor Analysis"
  },
  {
    "objectID": "content/index.html",
    "href": "content/index.html",
    "title": "Presentaciones, lecturas y actividades",
    "section": "",
    "text": "En esta sección se encuentran los documentos de presentación correspondientes a cada clase, lecturas y también actividades prácticas."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Metodología I - MCS",
    "section": "",
    "text": "Metodología I\n        \n        \n            Magister en Ciencias Sociales, mención Sociología de la Modernización\n        \n        \n            MCS7113 • Primer Semestre 2023Departamento de Sociología FACSOUniversidad de Chile\n        \n    \n    \n        \n    \n\n\n\n\n\nProfesores\n\n   Juan Carlos Castillo, Pablo Perez Ahumada & Kevin Carrasco\n   Departamento de Sociología FACSO - sala 328\n   juancastillov@uchile.cl, pabloperez@uchile.cl, kevin.carrasco@ug.uchile.cl\n   juankcastillo, pablo_perez_a, kevincarrascoq1\n   Reuniones\n\n\n\nInformación del curso\n\n   Viernes\n   Marzo 17–Julio 07, 2023\n   09:00-10:50 AM\n   Sala 119. Primer piso edificio nuevo FACSO\n   Slack\n\n\n\nContacto\nA través de correo"
  },
  {
    "objectID": "resource/01-resource.html",
    "href": "resource/01-resource.html",
    "title": "Práctica 1. Aproximación inicial a R",
    "section": "",
    "text": "Esta práctica tiene dos objetivos: 1) Generar un primer acercamiento al uso de R y Rstudio, conociendo su interfaz y sus principales funcionalidades y 2) revisar algunos procedimientos básicos de la preparación de datos con R, que son necesarios para luego poder aplicar los contenidos más específicos de este curso.\n\n\n\n\n\n\nAcceder a la página de posit, desarrollador del software desde octubre de 2022. Link directo a la descarga acá.\nInstalar R y Rstudio\n\n\n\nDescargar R\n\n\nSeleccionamos sistema operativo según corresponda\n\n\n\nDescargar R por primera vez y seguir instrucciones. En esta oportunidad trabajaremos con la última versión de R 4.2.2 \n\n\nDescargar RStudio\n\n\nDescarga directa en la página de inicio\n\n\nInstalar ambos archivos siguiendo las instrucciones de instalación\n\n\nAbrir RStudio. Se debería ver similar a esto:\n\n\n\nRecomendaciones generales:\n\n\nevitar uso de tilde, ñ, espacios y mayúsculas tanto en carpetas y archivos, así como también en los nombres de las variables\nal momento de hacer consultas sobre problemas en la ejecución del código, adjuntar la siguiente información:\n\n\nCódigo completo hasta que se produce el problema\nIndicar línea del código donde se produce el problema\nAdjuntar el resultado del output de la información de la sesión (sessionInfo())\n\n\n\n\n\nEn primer lugar vamos a abrir un archivo de R (script). Esto se puede hacer manualmente con File -> new file -> R script o directamente con ctrl + shift + N\nEsta es nuestra hoja de código, que utilizaremos para procesar bases de datos, modificar variables y crear tablas y gráficos.\n\n\nR puede ser una calculadora\n\n10 + 5 # ¿cuánto es 10 + 5?\n\n[1] 15\n\n\n\n10 * 5 # ¿cuánto es 10 * 5?\n\n[1] 50\n\n\nSe pueden crear objetos y asignarles valores\n\na <- 28\nb <- 8\n\na + b\n\n[1] 36\n\n\nO asignar operaciones a un objeto\n\nc <- a + b\n\nSin embargo, la mayor parte del tiempo usamos funciones que ya existen en R\n\nsum(28,8)\n\n[1] 36\n\n\n\nround(10.14536) #aproximar\n\n[1] 10\n\n\nY muchas de estas funciones que utilizamos en R están contenidas en librerías o paquetes (packages)\n\n\n\nLa lógica de R es instalar librerías (solo 1 vez, con install.packages(\"librería\")), y luego cargarlas cada vez que es necesario usarlas (con library(librería)). El problema de esto es que a veces no se sabe claramente qué librerías están instaladas y cuales no, lo que va a arrojar error al cargarlas. Y, como sucede en R, existe una librería para solucionar este problema que se llama pacman (package manager). Lo que hace pacman es cargar la librería, y si no está instalada, la instala y la carga:\nPara utilizar la primera vez (si es que no está instalada):\n\ninstall.packages(\"pacman\")\n\nY en adelante, las librerías se cargan así  pacman::p_load(libreria1,libreria2,libreriaX) :\n\npacman::p_load(dplyr, guaguas)\n\nInstalling package into '/home/juank/Dropbox/Rlibrary'\n(as 'lib' is unspecified)\n\n\n\nguaguas installed\n\n\nPara esta sesión las librerías que vamos a utilizar son:\n\ndplyr: ajuste general de datos\nguaguas: Paquete que contiene los datos de nombres de guaguas (bebés) registrados en Chile entre 1920 y 2021 según el Registro Civil e Identificación\n\n\n\n\nAjustar espacio de trabajo\nPrevio a la carga de nuestra base de datos, se recomienda ejecutar los siguientes comandos:\n\nrm(list=ls())       # borrar todos los objetos en el espacio de trabajo\noptions(scipen=999) # valores sin notación científica\n\nLa función rm(list=ls()) permite comenzar con un espacio de trabajo (environment) vacío y sin otros objetos. Así también, la función options(scipen=999) desactiva la notación científica, es decir, veremos los valores numéricos con todos sus decimales.\nDatos\nCargamos la base de datos desde el paquete (para otras bases de datos se deben importar de otra forma, esto es solo como ejemplo)\n\nbase <- guaguas\n\nConocemos las dimensiones de la base de datos\n\ndim(base)\n\n[1] 858782      5\n\n\nSon 858782 casos y 5 variables. Los nombres de estas variables son:\n\nnames(base)\n\n[1] \"anio\"       \"nombre\"     \"sexo\"       \"n\"          \"proporcion\"\n\n\nY la base se ve así:\n\nhead(base)\n\n# A tibble: 6 × 5\n   anio nombre sexo      n proporcion\n  <dbl> <chr>  <chr> <dbl>      <dbl>\n1  1920 María  F      2130     0.104 \n2  1920 José   M       984     0.0483\n3  1920 Juan   M       636     0.0312\n4  1920 Luis   M       631     0.0310\n5  1920 Rosa   F       426     0.0209\n6  1920 Ana    F       340     0.0167\n\n\nAhora probemos algunas funciones para seguir explorando la base\n\ntable(base$sexo)\n\n\n     F      I      M \n531038    318 327426 \n\n\nPodemos ver la cantidad de nombres “F” (femenino), “M” (masculino) e “I” (indefinido) inscritos entre 1920 y 2021.\nPueden buscar sus nombres y probar, utilizamos la funcion filter del paquete dplyr\n\nfilter(base, nombre==\"Kevin\")\n\n# A tibble: 63 × 5\n    anio nombre sexo      n proporcion\n   <dbl> <chr>  <chr> <dbl>      <dbl>\n 1  1931 Kevin  M         1 0.0000120 \n 2  1963 Kevin  M         1 0.0000035 \n 3  1964 Kevin  M         1 0.00000344\n 4  1967 Kevin  M         4 0.0000131 \n 5  1970 Kevin  M         6 0.0000210 \n 6  1971 Kevin  M         3 0.00000936\n 7  1972 Kevin  M         3 0.00000945\n 8  1973 Kevin  M         2 0.00000633\n 9  1974 Kevin  M         5 0.0000163 \n10  1976 Kevin  M         2 0.00000724\n# … with 53 more rows\n\n\nE incluso pueden ver la cantidad de personas con su nombre, en el mismo año que ustedes nacieron\n\nd <- filter(base, nombre==\"Kevin\" & anio==1996)\nsum(d$n)\n\n[1] 1312"
  },
  {
    "objectID": "resource/02-2-resource.html",
    "href": "resource/02-2-resource.html",
    "title": "Práctica 2.2 Organización de trabajo y operacionalización de variables",
    "section": "",
    "text": "El desarrollo de esta guía tiene por objetivo revisar algunos procedimientos básicos de la preparación de datos con R, que son necesarios para luego poder analizar e interpretar los datos.\nPor temas de orden y reproducibilidad, en este curso vamos a separar en dos momentos el trabajo con datos, y dos archivos de código correspondientes:\n\nPreparación corresponde a lo que se conoce generalmente como “limpieza”, es decir, realizar las modificaciones necesarias para poder efectuar los análisis. Estas modificaciones previas al análisis son necesarias ya que los datos originales con los que se va a trabajar en general no vienen perfectamente adaptados a los análisis que se quieren hacer. Por lo tanto, en cuanto a datos también hacemos la distinción entre datos originales y datos preparados (o procesados).\nAnálisis: se relaciona tanto con análisis descriptivos asociados a las preguntas de investigación y como también modelamiento de datos para contrastar hipótesis de investigación.\n\n\n\n\nTanto la preparación como el análisis (que son parte del concepto más general de procesamiento) quedan registrados cada uno en un archivo de código.\nArchivo de código R: archivo con extensión .R donde se almacena el código de análisis. Para generarlo desde RStudio: File > New File > R Script (o ctrl+shift+N), y para grabarlo File > Save (o ctrl+s), y darle nombre la primera vez (recordar: sin tilde ni ñ, y evitar espacios) \n\n\n\n\n\nRproject: Archivo con extensión .Rproj que permite agrupar todo tu trabajo en una carpeta que contiene todos los archivos vinculados al mismo, facilitando el manejo a través de carpetas.\nEncontrando la ruta a carpeta local: lo más fácil es crear la carpeta donde se desean guardar los datos desde el administrador de archivos del computador. Luego, posicionarse con el cursor sobre la carpeta y seleccionar “Propiedades”, en la ventana emergente debería aparecer la ruta hacia la carpeta en “Ubicación”. Copiar esa ruta y agregar al final el nombre de la carpeta (separada por slash)\nSobre los “slashes” (\\ o /): en la ruta las carpetas y el archivo final aparecen separados por slashes, que según el sistema utilizado pueden ser slash (/) o backslash (\\). En R por defecto se usa slash, pero en Windows backslash, por lo que si se usa Windows hay que reemplazarlos por backslash o también puede ser por un doble slash (//).\nPor temas de compatibilidad general, en las rutas se recomienda evitar tildes, eñes, espacios, mayúsculas y guiones bajos (_).\nEstructura de carpetas: para mantener el orden se sugiere seguir un protocolo de estructura de carpetas de proyecto, para lo que recomendamos el protocolo IPO, y que se adapta al flujo de trabajo presentado en la sección anterior. Básicamente son tres carpetas: input, procesamiento, output. En la carpeta input crear la subcarpeta data-orig para guardar datos originales, y data-proc para los procesados. En procesamiento se guardan los archivos de código y en output las tablas y los gráficos.\n\n\n\n\nEl documento de código de preparación posee 5 partes, más una sección de identificación inicial:\n\nIdentificación y descripción general: Título, autor(es), fecha, información breve sobre el contenido del documento\nLibrerías: cargar librerías a utilizar\nDatos: carga de datos\nSelección de variables a utilizar\nProcesamiento de variables: en este punto, por cada variable se realiza lo siguiente:\n\nDescriptivo básico\nRecodificación: datos perdidos y valores (en caso de ser necesario)\nEtiquetamiento: de variable y valores (en caso de ser necesario)\nOtros ajustes\n\nGeneración de base de datos preparada para el análisis.\n\nAl final de esta práctica la idea es que cada un_ elabore y entienda su propio documento de preparación de datos.\nEn el ejemplo vamos a procesar variables de formación ciudadana y variables de caracterización sociodemográfica utilizando los datos de la encuesta International Civic and Citizenship Education Study ICCS 2016 .\n\n\n\nICCS 2016 fue el cuarto proyecto realizado por la IEA en educación cívica, donde monitoreó las tendencias en el conocimiento y compromiso cívico durante siete años en los países que participaron en ICCS 2009.\nICCS evalúa a estudiantes de octavo grado, siempre que la edad promedio en este nivel de año sea de 13.5 años o más. En países donde la edad promedio de los estudiantes en el grado 8 era inferior a 13.5, el grado 9 se definió como la población objetivo.\nEl presente ejercicio tiene por objetivo procesar los datos para obtener las variables relevantes para el estudio de la Participación cívica, entendida como el grado en que los estudiantes participan en distintas instancias de toma de decisiones políticas, como la intención de voto, discusión de temas políticos y sociales o el centro de estudiantes, etc. Para ello, junto con variables de participación, consideraremos también el sexo de los estudiantes."
  },
  {
    "objectID": "resource/02-2-resource.html#librerias",
    "href": "resource/02-2-resource.html#librerias",
    "title": "Práctica 2.2 Organización de trabajo y operacionalización de variables",
    "section": "1. Librerías principales (de R) a utilizar en el análisis",
    "text": "1. Librerías principales (de R) a utilizar en el análisis\nComo sabemos, la lógica de R es instalar librerías (solo 1 vez, con install.packages(\"librería\")), y luego cargarlas cada vez que es necesario usarlas (con library(librería)). El problema de esto es que a veces no se sabe claramente qué librerías están instaladas y cuales no, lo que va a arrojar error al cargarlas. Y, como sucede en R, existe una librería para solucionar este problema que se llama pacman (package manager). Lo que hace pacman es cargar la librería, y si no está instalada, la instala y la carga:\nPara utilizar la primera vez (si es que no está instalada):\n\ninstall.packages(\"pacman\")\n\nY en adelante, las librerías se cargan así  pacman::p_load(libreria1,libreria2,libreriaX) :\n\npacman::p_load(dplyr, sjmisc, car, sjlabelled, stargazer, haven)\n\nPara esta sesión vamos a utilizar Las librerías que vamos a utilizar son:\n\ndplyr: ajuste general de datos\nsjmisc: descripción y exploración de base de datos\ncar: principalmente la función recode para recodificar/agrupar valores de variable\nstargazer: para tabla descriptiva\nhaven: Cargar y exportar bases de datos"
  },
  {
    "objectID": "resource/02-2-resource.html#cargar-base-de-datos",
    "href": "resource/02-2-resource.html#cargar-base-de-datos",
    "title": "Práctica 2.2 Organización de trabajo y operacionalización de variables",
    "section": "2. Cargar base de datos",
    "text": "2. Cargar base de datos\nAjustar espacio de trabajo\nPrevio a la carga de nuestra base de datos, se recomienda ejecutar los siguientes comandos:\n\nrm(list=ls())       # borrar todos los objetos en el espacio de trabajo\noptions(scipen=999) # valores sin notación científica\n\nLa función rm(list=ls()) permite comenzar con un espacio de trabajo (environment) vacío y sin otros objetos. Así también, la función options(scipen=999) desactiva la notación científica, es decir, veremos los valores numéricos con todos sus decimales.\nDatos\nLas bases de datos se pueden cargar de un archivo local o en línea. Para este caso utilizaremos un archivo local en formato .sav: Abrir bases de datos en otros formatos: Los formatos mas comunes en que se almacenan las bases de datos son .dta (Stata), .sav (Spss) y RData (R). Para abrir desde R utlilizamos la librería haven y sus funciones read_dta y read_sav según corresponda. Ej: datos <- read_dta(\"base_casen.dta\"). Recordar antes instalar/cargar la librería: pacman::p_load(haven) \n\niccs <- read_sav(\"input/data/original/ISGCHLC3.sav\", encoding = \"UTF-8\")\n\n\n\n\nLa base de datos aparece como un objeto en nuestro espacio de trabajo, con el nombre original con la que fue guardada (iccs):\nRealizamos un chequeo básico de la lectura de datos: nombres de las variables y tamaño de la base en términos de casos y variables (en este ejemplo, 5081 casos y 351 variables).\n\ndim(iccs) # dimension de la base\n\n[1] 5081  351\n\n\nY si se quiere revisar en formato de planilla de datos:\n\nView(iccs)"
  },
  {
    "objectID": "resource/02-2-resource.html#selección-de-variables-a-utilizar",
    "href": "resource/02-2-resource.html#selección-de-variables-a-utilizar",
    "title": "Práctica 2.2 Organización de trabajo y operacionalización de variables",
    "section": "3. Selección de variables a utilizar",
    "text": "3. Selección de variables a utilizar\nEste paso consiste en crear un subset reducido de datos que contenga solo las variables de interés. Para ello:\n\nSe identifica el nombre de las variables que registran la información de preguntas o items del instrumento: esto aparece en el libro de códigos y/o en el cuestionario, o también se puede hacer buscando en la base de datos mediante alguna palabra clave asociada a la pregunta. Por ejemplo, si queremos buscar variables asociadas a educación, utilizamos la función find_var (de sjmisc, librería que cargamos en el paso 1), que nos entrega nombre de la variable en columna var.name. Por ejemplo, si buscamos alguna variable asociada al concepto votar:\n\n\nfind_var(data = iccs,\"Vote\")\n\n  col.nr var.name\n1    179  IS3G31A\n2    180  IS3G31B\n3    189  IS3G31K\n4    190  IS3G31L\n5    191  IS3G32A\n                                                                                                               var.label\n1                        Participating in Society/When an adult, what do you think you will do/Vote in <local elections>\n2                     Participating in Society/When an adult, what do you think you will do/Vote in <national elections>\n3              Participating in Society/When an adult, what do you think you will do/Vote in <state, province elections>\n4                       Participating in Society/When an adult, what do you think you will do/Vote in European elections\n5 Participating in Society/How likely participate/Vote school election of <class representatives> or <school parliament>\n\n\nNos informa que hay una serie de variables relacionadas con votar.\nMediante la función select de dplyr, seleccionamos cada una de nuestras variables de interés y creamos una nueva base con el nombre proc_data, donde “proc” hace referencia a base procesada:\n\nproc_data <- iccs %>% select(IS3G31B, # Intención de Voto en elecciones nacionales\n                          IS3G31E, # Intención de unirse a un partido político\n                          IS3G31G, # Intencion candidato en elecciones locales\n                          S_GENDER) # genero \n\n# Comprobar\nnames(proc_data)\n\n[1] \"IS3G31B\"  \"IS3G31E\"  \"IS3G31G\"  \"S_GENDER\"\n\n\nMediante el comando get_label obtenemos el atributo label de las variables.\n\nsjlabelled::get_label(proc_data)\n\n                                                                                                          IS3G31B \n             \"Participating in Society/When an adult, what do you think you will do/Vote in <national elections>\" \n                                                                                                          IS3G31E \n                   \"Participating in Society/When an adult, what do you think you will do/Join a political party\" \n                                                                                                          IS3G31G \n\"Participating in Society/When an adult, what do you think you will do/Stand as a candidate in <local elections>\" \n                                                                                                         S_GENDER \n                                                                                                 \"Student gender\" \n\n\nPodemos ver que son largas o con códigos poco informativos, por lo tanto, es necesario cambiarlas por etiquetas más cortas y de fácil identificación."
  },
  {
    "objectID": "resource/02-2-resource.html#procesamiento-de-variables",
    "href": "resource/02-2-resource.html#procesamiento-de-variables",
    "title": "Práctica 2.2 Organización de trabajo y operacionalización de variables",
    "section": "4. Procesamiento de variables",
    "text": "4. Procesamiento de variables\nPara el procesamiento de cada variable se seguirá el siguiente flujo de trabajo:\n\nDescriptivo general\nRecodificación: de casos perdidos y otros valores (en caso necesario)\nEtiquetado: cambio de nombres de variables y valores (en caso necesario)\nOtros ajustes\n\nY se recomienda también un descriptivo final para revisar que el procesamiento de cada variable está ok.\n\n4.1 Intención de participación\nEn Latinobarómetro, lass variables que permiten medir la Confianza en instituciones políticas en Chile son las siguientes:\n\n\n\n\n\na. Descriptivo\nPara los descriptivos se utilizará la función frq, de la librería sjmisc:\n\nfrq(proc_data$IS3G31B)\n\nParticipating in Society/When an adult, what do you think you will do/Vote in <national elections> (x) <numeric> \n# total N=5081 valid N=4944 mean=1.77 sd=0.92\n\nValue |                         Label |    N | Raw % | Valid % | Cum. %\n-----------------------------------------------------------------------\n    1 |     I would certainly do this | 2441 | 48.04 |   49.37 |  49.37\n    2 |      I would probably do this | 1589 | 31.27 |   32.14 |  81.51\n    3 |  I would probably not do this |  534 | 10.51 |   10.80 |  92.31\n    4 | I would certainly not do this |  380 |  7.48 |    7.69 | 100.00\n    7 |                       Invalid |    0 |  0.00 |    0.00 | 100.00\n    8 |              Not administered |    0 |  0.00 |    0.00 | 100.00\n    9 |                       Omitted |    0 |  0.00 |    0.00 | 100.00\n <NA> |                          <NA> |  137 |  2.70 |    <NA> |   <NA>\n\n\nEn esta variable vemos valores asociados a la opción “invalid” (7), “Not administered” (8) y “ommited” (9), que corresponde definirlos como casos perdidos (en el caso de R, como casos NA), pero vienen recodificados como NA en la base (hay 137 NA). El resto de los valores y etiquetas se encuentran en un orden contraintuitivo (mayor valor indica menos intención de voto), así que en la recodificiación nos haremos cargo de reordenar las categorías.\nb. Recodificación\nPara reordenar las categorías volvemos a utilizar la función recode, de la librería car\n\nproc_data$IS3G31B <- recode(proc_data$IS3G31B, \"1=4; 2=3; 3=2; 4=1\")\nproc_data$IS3G31E <- recode(proc_data$IS3G31E, \"1=4; 2=3; 3=2; 4=1\")\nproc_data$IS3G31G <- recode(proc_data$IS3G31G, \"1=4; 2=3; 3=2; 4=1\")\n\nc - Etiquetado\nVamos a dar un nombre más sustantivo a las variables con la función rename, de la librería dplyr:\n\nproc_data <- proc_data %>% rename(\"voto\"=IS3G31B, # Intencion de voto\n                                  \"candidato\"=IS3G31E, # Intencion de ser candidato\n                                  \"partido\"=IS3G31G) # Intencion de unirse a partido politico\n\nAdemás de cambiar el nombre, queremos cambiar las etiquetas de las variables.\n\nget_label(proc_data$voto)\n\n[1] \"Participating in Society/When an adult, what do you think you will do/Vote in <national elections>\"\n\nproc_data$voto <- set_label(x = proc_data$voto,label = \"Intencion de voto\")\n\nget_label(proc_data$candidato)\n\n[1] \"Participating in Society/When an adult, what do you think you will do/Join a political party\"\n\nproc_data$candidato  <- set_label(x = proc_data$candidato, label = \"Intencion de ser candidato\")\n\nget_label(proc_data$partido)\n\n[1] \"Participating in Society/When an adult, what do you think you will do/Stand as a candidate in <local elections>\"\n\nproc_data$partido  <- set_label(x = proc_data$partido, label = \"Intencion de unirse a partido politico\")\n\nd. Otros ajustes\nPara este caso vamos a crear una variable que sea el promedio de los tres items de intención de participación\n\nproc_data <- proc_data %>% rowwise() %>% mutate(int_part = mean(c(voto, candidato, partido), na.rm = T))\nsummary(proc_data$int_part)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  1.000   2.000   2.333   2.428   3.000   4.000     125 \n\n\n\nget_label(proc_data$int_part)\n\nNULL\n\n\nVemos que no tiene etiqueta.\n\nproc_data$int_part  <- set_label(x = proc_data$int_part, label = \"Intención de participación\")\n\nRevisión final\nNuevamente un descriptivo de cada variable para confirmar que el procesamiento está ok:\n\nfrq(proc_data$voto)\n\nIntencion de voto (x) <numeric> \n# total N=5081 valid N=4944 mean=3.23 sd=0.92\n\nValue |                         Label |    N | Raw % | Valid % | Cum. %\n-----------------------------------------------------------------------\n    1 |     I would certainly do this |  380 |  7.48 |    7.69 |   7.69\n    2 |      I would probably do this |  534 | 10.51 |   10.80 |  18.49\n    3 |  I would probably not do this | 1589 | 31.27 |   32.14 |  50.63\n    4 | I would certainly not do this | 2441 | 48.04 |   49.37 | 100.00\n    7 |                       Invalid |    0 |  0.00 |    0.00 | 100.00\n    8 |              Not administered |    0 |  0.00 |    0.00 | 100.00\n    9 |                       Omitted |    0 |  0.00 |    0.00 | 100.00\n <NA> |                          <NA> |  137 |  2.70 |    <NA> |   <NA>\n\nfrq(proc_data$candidato)\n\nIntencion de ser candidato (x) <numeric> \n# total N=5081 valid N=4922 mean=2.07 sd=0.93\n\nValue |                         Label |    N | Raw % | Valid % | Cum. %\n-----------------------------------------------------------------------\n    1 |     I would certainly do this | 1479 | 29.11 |   30.05 |  30.05\n    2 |      I would probably do this | 2102 | 41.37 |   42.71 |  72.75\n    3 |  I would probably not do this |  859 | 16.91 |   17.45 |  90.21\n    4 | I would certainly not do this |  482 |  9.49 |    9.79 | 100.00\n    7 |                       Invalid |    0 |  0.00 |    0.00 | 100.00\n    8 |              Not administered |    0 |  0.00 |    0.00 | 100.00\n    9 |                       Omitted |    0 |  0.00 |    0.00 | 100.00\n <NA> |                          <NA> |  159 |  3.13 |    <NA> |   <NA>\n\nfrq(proc_data$partido)\n\nIntencion de unirse a partido politico (x) <numeric> \n# total N=5081 valid N=4939 mean=1.98 sd=0.93\n\nValue |                         Label |    N | Raw % | Valid % | Cum. %\n-----------------------------------------------------------------------\n    1 |     I would certainly do this | 1741 | 34.26 |   35.25 |  35.25\n    2 |      I would probably do this | 2015 | 39.66 |   40.80 |  76.05\n    3 |  I would probably not do this |  739 | 14.54 |   14.96 |  91.01\n    4 | I would certainly not do this |  444 |  8.74 |    8.99 | 100.00\n    7 |                       Invalid |    0 |  0.00 |    0.00 | 100.00\n    8 |              Not administered |    0 |  0.00 |    0.00 | 100.00\n    9 |                       Omitted |    0 |  0.00 |    0.00 | 100.00\n <NA> |                          <NA> |  142 |  2.79 |    <NA> |   <NA>\n\n\nVemos que los valores (labels) de cada categoría de las primeras variables que recodificamos no se corresponden con el nuevo valor. Para re-etiquetar valores usamos la función set_labels, de la librería sjlabelled. Aprovechamos también de pasarlas a español\n\nproc_data$voto <- set_labels(proc_data$voto,\n            labels=c( \"Ciertamente no lo haria\"=1,\n                      \"Probablemente no lo haria\"=2,\n                      \"Probablemente lo haria\"=3,\n                      \"Ciertamente lo haria\"=4))\n\nproc_data$candidato <- set_labels(proc_data$candidato,\n            labels=c( \"Ciertamente no lo haria\"=1,\n                      \"Probablemente no lo haria\"=2,\n                      \"Probablemente lo haria\"=3,\n                      \"Ciertamente lo haria\"=4))\n\nproc_data$partido <- set_labels(proc_data$partido,\n            labels=c( \"Ciertamente no lo haria\"=1,\n                      \"Probablemente no lo haria\"=2,\n                      \"Probablemente lo haria\"=3,\n                      \"Ciertamente lo haria\"=4))\n\ny volvemos a revisar\n\nfrq(proc_data$voto)\n\nIntencion de voto (x) <numeric> \n# total N=5081 valid N=4944 mean=3.23 sd=0.92\n\nValue |                     Label |    N | Raw % | Valid % | Cum. %\n-------------------------------------------------------------------\n    1 |   Ciertamente no lo haria |  380 |  7.48 |    7.69 |   7.69\n    2 | Probablemente no lo haria |  534 | 10.51 |   10.80 |  18.49\n    3 |    Probablemente lo haria | 1589 | 31.27 |   32.14 |  50.63\n    4 |      Ciertamente lo haria | 2441 | 48.04 |   49.37 | 100.00\n <NA> |                      <NA> |  137 |  2.70 |    <NA> |   <NA>\n\nfrq(proc_data$partido)\n\nIntencion de unirse a partido politico (x) <numeric> \n# total N=5081 valid N=4939 mean=1.98 sd=0.93\n\nValue |                     Label |    N | Raw % | Valid % | Cum. %\n-------------------------------------------------------------------\n    1 |   Ciertamente no lo haria | 1741 | 34.26 |   35.25 |  35.25\n    2 | Probablemente no lo haria | 2015 | 39.66 |   40.80 |  76.05\n    3 |    Probablemente lo haria |  739 | 14.54 |   14.96 |  91.01\n    4 |      Ciertamente lo haria |  444 |  8.74 |    8.99 | 100.00\n <NA> |                      <NA> |  142 |  2.79 |    <NA> |   <NA>\n\n\n\n4.2. Sexo\n\n[S_GENDER] = Sexo\n\na. Descriptivo\n\nfrq(proc_data$S_GENDER)\n\nStudent gender (x) <numeric> \n# total N=5081 valid N=5081 mean=0.49 sd=0.50\n\nValue |            Label |    N | Raw % | Valid % | Cum. %\n----------------------------------------------------------\n    0 |              Boy | 2577 | 50.72 |   50.72 |  50.72\n    1 |             Girl | 2504 | 49.28 |   49.28 | 100.00\n    7 |          Invalid |    0 |  0.00 |    0.00 | 100.00\n    8 | Not administered |    0 |  0.00 |    0.00 | 100.00\n    9 |          Omitted |    0 |  0.00 |    0.00 | 100.00\n <NA> |             <NA> |    0 |  0.00 |    <NA> |   <NA>\n\n\nb. Recodificación\nEsta variable generalmente no tiene problemas de etiquetado, viene también con niños=0 y niñas=1\nc. Etiquetado\nCambio de nombre de la variable\n\nproc_data <- proc_data %>% rename(\"sexo\"=S_GENDER)\n\nPodemos pasar las categorías a español:\n\nproc_data$sexo <- set_labels(proc_data$sexo,\n            labels=c( \"Ninios\"=0,\n                      \"Ninias\"=1))\n\nTambién queremos cambiar la etiqueta de la variable.\n\nget_label(proc_data$sexo)\n\n[1] \"Student gender\"\n\nproc_data$sexo <- set_label(x = proc_data$sexo,label = \"Sexo\")\n\nRevisar con un nuevo descriptivo:\n\nfrq(proc_data$sexo)\n\nSexo (x) <numeric> \n# total N=5081 valid N=5081 mean=0.49 sd=0.50\n\nValue |  Label |    N | Raw % | Valid % | Cum. %\n------------------------------------------------\n    0 | Ninios | 2577 | 50.72 |   50.72 |  50.72\n    1 | Ninias | 2504 | 49.28 |   49.28 | 100.00\n <NA> |   <NA> |    0 |  0.00 |    <NA> |   <NA>"
  },
  {
    "objectID": "resource/02-2-resource.html#generación-de-base-de-datos-procesada-para-el-análisis",
    "href": "resource/02-2-resource.html#generación-de-base-de-datos-procesada-para-el-análisis",
    "title": "Práctica 2.2 Organización de trabajo y operacionalización de variables",
    "section": "5. Generación de base de datos procesada para el análisis",
    "text": "5. Generación de base de datos procesada para el análisis\nAntes de guardar la base procesada, revisamos nuevamente todas las variables con una tabla descriptiva general mediante la función stargazer (de la librería homónima)\nPrimero vamos a reformatear el objeto proc_data como base de datos (as.data.frame), paso necesario para que sea reconocido como tal por stargazer\n\nproc_data <-as.data.frame(proc_data)\nstargazer(proc_data, type=\"text\")\n\n\n==========================================\nStatistic   N   Mean  St. Dev.  Min   Max \n------------------------------------------\nvoto      4,944 3.232  0.925     1     4  \ncandidato 4,922 2.070  0.928     1     4  \npartido   4,939 1.977  0.928     1     4  \nsexo      5,081 0.493  0.500     0     1  \nint_part  4,956 2.428  0.726   1.000 4.000\n------------------------------------------\n\n\n\nSi se desea modificar las columnas que aparecen en la tabla se puede ocupar la opción summary.stat, donde se pueden especificar:\n\n“max” maximum\n“mean” mean\n“median” median\n“min” minimum\n“n” number of observations\n“p25” 25th percentile\n“p75” 75th percentile\n“sd” standard deviation\n\nPor ejemplo, si quiero una tabla solo con promedio, n, sd y p75: stargazer(data, type=\"text\", summary.stat = c(\"mean\", \"n\", \"sd\", \"p75\"))\n\n\nGuardar base de datos procesada: en carpeta local La ruta hacia su carpeta local si está trabajando en windows debería ser algo como “C:/Users/Lenovo/Clases/y aquí nombre del archivo a grabar\n\nEl comando para guardar es save. En este caso, seguimos una estructura de carpetas de datos, separando en una carpeta los datos originales, y en otra (proc) los datos procesados:\n\nsave(proc_data,file = \"input/data/proc/iccs_proc.RData\")"
  },
  {
    "objectID": "resource/02-2-resource.html#descriptivos-básicos-de-las-variables",
    "href": "resource/02-2-resource.html#descriptivos-básicos-de-las-variables",
    "title": "Práctica 2.2 Organización de trabajo y operacionalización de variables",
    "section": "Descriptivos básicos de las variables",
    "text": "Descriptivos básicos de las variables\nPodemos conocer ciertas medidas de tendencia central utilizando algunas funciones de dplyr\n\nMedia por grupos\n\nproc_data %>% dplyr::group_by(sexo) %>% summarise(mean(int_part, na.rm=TRUE))\n\n# A tibble: 2 × 2\n  sexo       `mean(int_part, na.rm = TRUE)`\n  <dbl+lbl>                           <dbl>\n1 0 [Ninios]                           2.46\n2 1 [Ninias]                           2.40\n\n\n\n\nRepresentación\n\nlibrary(ggplot2)\n\n\nAttaching package: 'ggplot2'\n\n\nThe following object is masked from 'package:sjlabelled':\n\n    as_label\n\nproc_data %>% na.omit() %>% \n  ggplot(aes(x=as_factor(voto))) +\n  geom_bar()+\n  theme_bw()"
  },
  {
    "objectID": "resource/02-resource.html",
    "href": "resource/02-resource.html",
    "title": "Práctica 2. Operacionalización de variables",
    "section": "",
    "text": "El desarrollo de esta guía tiene por objetivo revisar algunos procedimientos básicos de la preparación de datos con R, que son necesarios para luego poder analizar e interpretar los datos.\nPor temas de orden y reproducibilidad, en este curso vamos a separar en dos momentos el trabajo con datos, y dos archivos de código correspondientes:\n\nPreparación corresponde a lo que se conoce generalmente como “limpieza”, es decir, realizar las modificaciones necesarias para poder efectuar los análisis. Estas modificaciones previas al análisis son necesarias ya que los datos originales con los que se va a trabajar en general no vienen perfectamente adaptados a los análisis que se quieren hacer. Por lo tanto, en cuanto a datos también hacemos la distinción entre datos originales y datos preparados (o procesados).\nAnálisis: se relaciona tanto con análisis descriptivos asociados a las preguntas de investigación y como también modelamiento de datos para contrastar hipótesis de investigación.\n\n\n\n\nTanto la preparación como el análisis (que son parte del concepto más general de procesamiento) quedan registrados cada uno en un archivo de código.\nArchivo de código R: archivo con extensión .R donde se almacena el código de análisis. Para generarlo desde RStudio: File > New File > R Script (o ctrl+shift+N), y para grabarlo File > Save (o ctrl+s), y darle nombre la primera vez (recordar: sin tilde ni ñ, y evitar espacios) \nEl documento de código de preparación posee 5 partes, más una sección de identificación inicial:\n\nIdentificación y descripción general: Título, autor(es), fecha, información breve sobre el contenido del documento\nLibrerías: cargar librerías a utilizar\nDatos: carga de datos\nSelección de variables a utilizar\nProcesamiento de variables: en este punto, por cada variable se realiza lo siguiente:\n\nDescriptivo básico\nRecodificación: datos perdidos y valores (en caso de ser necesario)\nEtiquetamiento: de variable y valores (en caso de ser necesario)\nOtros ajustes\n\nGeneración de base de datos preparada para el análisis.\n\nAl final de esta práctica la idea es que cada un_ elabore y entienda su propio documento de preparación de datos.\nEn el ejemplo vamos a procesar variables de confianza en instituciones políticas y variables de caracterización sociodemográfica utilizando los datos de la encuesta Latinobarómetro .\n\n\n\n\nLatinobarómetro es un estudio de opinión pública que aplica anualmente alrededor de 20.000 entrevistas en 18 países de América Latina representando a más de 600 millones de habitantes\n“Los gobiernos latinoamericanos, que venían en declive junto con sus democracias desde inicios de la década de 2010, como reflejan los datos de Latinobarómetro, llegaron a fines de 2018 al annus horribilis con la caída de Nicaragua y Venezuela desde su condición de democracias para entrar en la categoría de autocracias y dictadura.\nDe los hiperpresidentes de la primera década del siglo con altos niveles de crecimiento en todos los países y altos niveles de aprobación, la región pasó en la segunda década a los subpresidentes, con una baja en aprobación de gobierno a la mitad, en menos de 10 años. Este rechazo al desempeño de las elites gobernantes, indica su fracaso a fines de 2019 en varios países de la región.” (Latinobarómetro, informe 2021, p. 7)\nEl presente ejercicio tiene por objetivo el procesar los datos para obtener las variables relevantes para el estudio de la Confianza en instituciones políticas, entendida como el grado en que los individuos confian en distintas instituciones políticas a nivel nacional, como el gobierno, la justicia, los partidos políticos, etc. Para ello, junto con variables de confianza, consideraremos también variables de estatus (educación), y variables de caracterización sociodemográfica (sexo y edad)."
  },
  {
    "objectID": "resource/02-resource.html#librerias",
    "href": "resource/02-resource.html#librerias",
    "title": "Práctica 2. Operacionalización de variables",
    "section": "1. Librerías principales (de R) a utilizar en el análisis",
    "text": "1. Librerías principales (de R) a utilizar en el análisis\nComo sabemos, la lógica de R es instalar librerías (solo 1 vez, con install.packages(\"librería\")), y luego cargarlas cada vez que es necesario usarlas (con library(librería)). El problema de esto es que a veces no se sabe claramente qué librerías están instaladas y cuales no, lo que va a arrojar error al cargarlas. Y, como sucede en R, existe una librería para solucionar este problema que se llama pacman (package manager). Lo que hace pacman es cargar la librería, y si no está instalada, la instala y la carga:\nPara utilizar la primera vez (si es que no está instalada):\n\ninstall.packages(\"pacman\")\n\nY en adelante, las librerías se cargan así  pacman::p_load(libreria1,libreria2,libreriaX) :\n\npacman::p_load(dplyr, sjmisc, car, sjlabelled, stargazer, haven)\n\nPara esta sesión vamos a utilizar Las librerías que vamos a utilizar son:\n\ndplyr: ajuste general de datos\nsjmisc: descripción y exploración de base de datos\ncar: principalmente la función recode para recodificar/agrupar valores de variable\nstargazer: para tabla descriptiva"
  },
  {
    "objectID": "resource/02-resource.html#cargar-base-de-datos",
    "href": "resource/02-resource.html#cargar-base-de-datos",
    "title": "Práctica 2. Operacionalización de variables",
    "section": "2. Cargar base de datos",
    "text": "2. Cargar base de datos\nAjustar espacio de trabajo\nPrevio a la carga de nuestra base de datos, se recomienda ejecutar los siguientes comandos:\n\nrm(list=ls())       # borrar todos los objetos en el espacio de trabajo\noptions(scipen=999) # valores sin notación científica\n\nLa función rm(list=ls()) permite comenzar con un espacio de trabajo (environment) vacío y sin otros objetos. Así también, la función options(scipen=999) desactiva la notación científica, es decir, veremos los valores numéricos con todos sus decimales.\nDatos\nLas bases de datos se pueden cargar de un archivo local o en línea. Para este caso utilizaremos un archivo en línea que viene en formato RData: latinobarometro2020.RData. Abrir bases de datos en otros formatos: Los formatos mas comunes en que se almacenan las bases de datos son .dta (Stata), .sav (Spss) y RData (R). Para abrir desde R utlilizamos la librería haven y sus funciones read_dta y read_sav según corresponda. Ej: datos <- read_dta(\"base_casen.dta\"). Recordar antes instalar/cargar la librería: pacman::p_load(haven) \n\n#cargamos la base de datos desde internet\nload(url(\"https://github.com/Kevin-carrasco/metod1-MCS/raw/main/files/data/external_data/latinobarometro2020.RData\"))\n\no de manera local:\n\nlatinobarometro2020 <- read_dta(\"../files/data/external_data/latinobarometro2020.dta\", encoding = \"UTF-8\")\n\nLa base de datos aparece como un objeto en nuestro espacio de trabajo, con el nombre original con la que fue guardada (elsoc_2016):\n\nRealizamos un chequeo básico de la lectura de datos: nombres de las variables y tamaño de la base en términos de casos y variables (en este ejemplo, 20204 casos y 408 variables).\n\ndim(latinobarometro2020) # dimension de la base\n\n[1] 20204   408\n\n\nY si se quiere revisar en formato de planilla de datos:\n\nView(latinobarometro2020)"
  },
  {
    "objectID": "resource/02-resource.html#selección-de-variables-a-utilizar",
    "href": "resource/02-resource.html#selección-de-variables-a-utilizar",
    "title": "Práctica 2. Operacionalización de variables",
    "section": "3. Selección de variables a utilizar",
    "text": "3. Selección de variables a utilizar\nEste paso consiste en crear un subset reducido de datos que contenga solo las variables de interés. Para ello:\n\nSe identifica el nombre de las variables que registran la información de preguntas o items del instrumento: esto aparece en el libro de códigos y/o en el cuestionario, o también se puede hacer buscando en la base de datos mediante alguna palabra clave asociada a la pregunta. Por ejemplo, si queremos buscar variables asociadas a educación, utilizamos la función find_var (de sjmisc, librería que cargamos en el paso 1), que nos entrega nombre de la variable en columna var.name. Por ejemplo, si buscamos alguna variable asociada al concepto Confianza:\n\n\nfind_var(data = latinobarometro2020,\"Confianza\")\n\n   col.nr   var.name\n1      36    p9stgbs\n2      41 P13STGBS_A\n3      42 P13STGBS_B\n4      43    p13st_c\n5      44    p13st_d\n6      45    p13st_e\n7      46    p13st_f\n8      47    p13st_g\n9      48    p13st_h\n10     49    p13st_i\n11     51    p15st_a\n12     52    p15st_b\n13     53    p15st_c\n14     54    p15st_d\n15     55    p15st_e\n16     56    p15st_f\n17     57    p15st_g\n18     58     p15n_h\n19     59     p15n_i\n20     60     p15n_j\n21     61     p15n_k\n22    154     p36n_a\n23    155     p36n_b\n24    160  P36STMB_A\n25    161  P36STMB_B\n26    162  P36STMB_C\n27    163  P36STMB_D\n                                                                          var.label\n1                                                   P9STGBS Confianza Interpersonal\n2                                       P13STGBS.A Confianza en las Fuerzas Armadas\n3                                  P13STGBS.B Confianza en la Policía / Carabineros\n4                                                   P13ST.C Confianza en la Iglesia\n5                                                  P13ST.D Confianza en el Congreso\n6                                                  P13ST.E Confianza en el Gobierno\n7                                            P13ST.F Confianza en el Poder Judicial\n8                                       P13ST.G Confianza en los Partidos Políticos\n9                           P13ST.H Confianza en: La institución Electoral del país\n10                                              P13ST.I Confianza en: El presidente\n11 P15ST.A Confianza en que las instituciones operan para mejorar nuestra calidad d\n12 P15ST.B Confianza en que las instituciones operan para mejorar nuestra calidad d\n13 P15ST.C Confianza en que las instituciones operan para mejorar nuestra calidad d\n14 P15ST.D Confianza en que las instituciones operan para mejorar nuestra calidad d\n15 P15ST.E Confianza en que las instituciones operan para mejorar nuestra calidad d\n16 P15ST.F Confianza en que las instituciones operan para mejorar nuestra calidad d\n17 P15ST.G Confianza en que las instituciones operan para mejorar nuestra calidad d\n18 P15N.H Confianza en que las instituciones operan para mejorar nuestra calidad de\n19 P15N.I Confianza en que las instituciones operan para mejorar nuestra calidad de\n20 P15N.J Confianza en que las instituciones operan para mejorar nuestra calidad de\n21 P15N.K Confianza en que las instituciones operan para mejorar nuestra calidad de\n22                        P36N.A Confianza en las Fuerzas Armadas de Estados Unidos\n23                                   P36N.B Confianza en las fuerzas Armadas Chinas\n24                    P36STMB.A Confianza en el FMI (Fondo Monetario Internacional)\n25               P36STMB.B Confianza en el BID (Banco Interamericano de Desarrollo)\n26            P36STMB.C Confianza en el CAF (Banco de Desarrollo de América Latina)\n27                                          P36STMB.D Confianza en el Banco Mundial\n\n\nNos informa que hay una serie de variables relacionadas con confianza interpersonal y con instituciones. Probemos con la variable p13st_e.\nMediante la función select de dplyr, seleccionamos cada una de nuestras variables de interés y creamos una nueva base con el nombre proc_data, donde “proc” hace referencia a base procesada:\n\nproc_data <- latinobarometro2020 %>% select(p13st_e, # Confianza en el Gobierno\n                          p13st_d, # Confianza en el congreso\n                          p13st_f, # Confianza en el Poder Judicial\n                          p13st_g, # Confianza en los partidos políticos\n                          reeduc_1,# nivel educacional\n                          sexo,# sexo\n                          edad,# edad\n                          idenpa) # pais \n\n# Comprobar\nnames(proc_data)\n\n[1] \"p13st_e\"  \"p13st_d\"  \"p13st_f\"  \"p13st_g\"  \"reeduc_1\" \"sexo\"     \"edad\"    \n[8] \"idenpa\"  \n\n\nMediante el comando get_label obtenemos el atributo label de las variables.\n\nsjlabelled::get_label(proc_data)\n\n                                                             p13st_e \n                                  \"P13ST.E Confianza en el Gobierno\" \n                                                             p13st_d \n                                  \"P13ST.D Confianza en el Congreso\" \n                                                             p13st_f \n                            \"P13ST.F Confianza en el Poder Judicial\" \n                                                             p13st_g \n                       \"P13ST.G Confianza en los Partidos Políticos\" \n                                                            reeduc_1 \n\"REEDUC.1 Nivel de estudios alcanzado - Entrevistado (recodificado)\" \n                                                                sexo \n                                                         \"SEXO Sexo\" \n                                                                edad \n                                                         \"EDAD Edad\" \n                                                              idenpa \n                                    \"IDENPA Identificación del País\" \n\n\nPodemos ver que son largas o con códigos poco informativos, por lo tanto, es necesario cambiarlas por etiquetas más cortas y de fácil identificación.\n\n\n\nPara facilitar el análisis, vamos a filtrar la base de datos para quedarnos solo con los casos de Chile. Para esto utilizamos la función filter de dplyr. Si revisamos el libro de códigos, el identificador de Chile es 152\n\nproc_data <- proc_data %>% dplyr::filter(idenpa==152)"
  },
  {
    "objectID": "resource/02-resource.html#procesamiento-de-variables",
    "href": "resource/02-resource.html#procesamiento-de-variables",
    "title": "Práctica 2. Operacionalización de variables",
    "section": "4. Procesamiento de variables",
    "text": "4. Procesamiento de variables\nPara el procesamiento de cada variable se seguirá el siguiente flujo de trabajo:\n\nDescriptivo general\nRecodificación: de casos perdidos y otros valores (en caso necesario)\nEtiquetado: cambio de nombres de variables y valores (en caso necesario)\nOtros ajustes\n\nY se recomienda también un descriptivo final para revisar que el procesamiento de cada variable está ok.\n\n4.1 Confianza en el Gobierno\nEn Latinobarómetro, lass variables que permiten medir la Confianza en instituciones políticas en Chile son las siguientes:\n\n[p13st_e]: “P13ST.E Confianza en el Gobierno” (1 = Mucha; 4 = Ninguna)\n[p13st_d]: “P13ST.D Confianza en el Congreso” (1 = Mucha; 4 = Ninguna)\n[p13st_f]: “P13ST.F Confianza en el Poder Judicial” (1 = Mucha; 4 = Ninguna)\n[p13st_g]: “P13ST.G Confianza en los Partidos Políticos” (1 = Mucha; 4 = Ninguna)\n\na. Descriptivo\nPara los descriptivos se utilizará la función frq, de la librería sjmisc:\n\nfrq(proc_data$p13st_e)\n\nx <numeric> \n# total N=1200 valid N=1200 mean=3.27 sd=0.99\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n   -2 |   8 |  0.67 |    0.67 |   0.67\n   -1 |  11 |  0.92 |    0.92 |   1.58\n    1 |  23 |  1.92 |    1.92 |   3.50\n    2 | 176 | 14.67 |   14.67 |  18.17\n    3 | 358 | 29.83 |   29.83 |  48.00\n    4 | 624 | 52.00 |   52.00 | 100.00\n <NA> |   0 |  0.00 |    <NA> |   <NA>\n\n\nEn esta variable vemos valores asociados a la opción “No contesta” (-2) y “No sabe” (-1), que corresponde definirlos como casos perdidos (en el caso de R, como casos NA). El resto de los valores y etiquetas se encuentran en un orden contraintuitivo (mayor valor indica menos confianza), así que en la recodificiación nos haremos cargo de los casos perdidos y de reordenar las categorías.\nb. Recodificación\nPara recodificar utilizamos la función recode, de la librería car\n\nproc_data$p13st_e <- recode(proc_data$p13st_e, \"c(-2,-1)=NA\")\nproc_data$p13st_d <- recode(proc_data$p13st_d, \"c(-2,-1)=NA\")\nproc_data$p13st_f <- recode(proc_data$p13st_f, \"c(-2,-1)=NA\")\nproc_data$p13st_g <- recode(proc_data$p13st_g, \"c(-2,-1)=NA\")\n\nnota: con la función set_na de la librería sjmisc podemos recodificar toda la base de datos con un solo código, pero debemos estar completamente segur-s de que estos valores no tienen otra categoría asociada en otra variable.\n\nproc_data <- proc_data %>% set_na(., na = c(-2, -1))\n\nPara reordenar las categorías volvemos a utilizar la función recode, de la librería car\n\nproc_data$p13st_e <- recode(proc_data$p13st_e, \"1=3; 2=2; 3=1; 4=0\")\nproc_data$p13st_d <- recode(proc_data$p13st_d, \"1=3; 2=2; 3=1; 4=0\")\nproc_data$p13st_f <- recode(proc_data$p13st_f, \"1=3; 2=2; 3=1; 4=0\")\nproc_data$p13st_g <- recode(proc_data$p13st_g, \"1=3; 2=2; 3=1; 4=0\")\n\nc - Etiquetado\nVamos a dar un nombre más sustantivo a las variables con la función rename, de la librería dplyr:\n\nproc_data <- proc_data %>% rename(\"conf_gob\"=p13st_e, # Confianza en el gobierno\n                                  \"conf_cong\"=p13st_d, # Confianza en el congreso\n                                  \"conf_jud\"=p13st_f, # Confianza en el Poder Judicial\n                                  \"conf_partpol\"=p13st_g) # Confianza en los partidos políticos \n\nnota: recodificación más rápida si estamos segur-s de todos los valores\n\nproc_data <- proc_data %>% mutate_at(vars(starts_with(\"conf\")), ~(4-.))\n\nAdemás de cambiar el nombre, queremos cambiar las etiquetas de las variables.\n\nproc_data$conf_gob <- set_label(x = proc_data$conf_gob,label = \"Confianza: Gobierno\")\nget_label(proc_data$conf_gob)\n\n[1] \"Confianza: Gobierno\"\n\nproc_data$conf_cong  <- set_label(x = proc_data$conf_cong, label = \"Confianza: Congreso\")\nget_label(proc_data$conf_cong)\n\n[1] \"Confianza: Congreso\"\n\nproc_data$conf_jud  <- set_label(x = proc_data$conf_jud, label = \"Confianza: Poder judicial\")\nget_label(proc_data$conf_jud)\n\n[1] \"Confianza: Poder judicial\"\n\nproc_data$conf_partpol  <- set_label(x = proc_data$conf_partpol, label = \"Confianza: Partidos politicos\")\nget_label(proc_data$conf_partpol)\n\n[1] \"Confianza: Partidos politicos\"\n\n\nd. Otros ajustes\nPara este caso vamos a crear una variable que sea la suma de los cuatro items de confianza.\n\nproc_data$conf_inst <- (proc_data$conf_gob+proc_data$conf_cong+proc_data$conf_jud+proc_data$conf_partpol)\nsummary(proc_data$conf_inst)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00    0.00    2.00    2.42    4.00   12.00      38 \n\n\n\nget_label(proc_data$conf_inst)\n\n[1] \"Confianza: Gobierno\"\n\n\nVemos que una etiqueta de la variable anterior.\n\nproc_data$conf_inst  <- set_label(x = proc_data$conf_inst, label = \"Confianza en instituciones\")\n\nRevisión final\nNuevamente un descriptivo de cada variable para confirmar que el procesamiento está ok:\n\nfrq(proc_data$conf_gob)\n\nConfianza: Gobierno (x) <numeric> \n# total N=1200 valid N=1181 mean=0.66 sd=0.80\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n    0 | 624 | 52.00 |   52.84 |  52.84\n    1 | 358 | 29.83 |   30.31 |  83.15\n    2 | 176 | 14.67 |   14.90 |  98.05\n    3 |  23 |  1.92 |    1.95 | 100.00\n <NA> |  19 |  1.58 |    <NA> |   <NA>\n\nfrq(proc_data$conf_cong)\n\nConfianza: Congreso (x) <numeric> \n# total N=1200 valid N=1178 mean=0.59 sd=0.71\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n    0 | 628 | 52.33 |   53.31 |  53.31\n    1 | 408 | 34.00 |   34.63 |  87.95\n    2 | 134 | 11.17 |   11.38 |  99.32\n    3 |   8 |  0.67 |    0.68 | 100.00\n <NA> |  22 |  1.83 |    <NA> |   <NA>\n\nfrq(proc_data$conf_inst)\n\nConfianza en instituciones (x) <numeric> \n# total N=1200 valid N=1162 mean=2.42 sd=2.49\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n    0 | 397 | 33.08 |   34.17 |  34.17\n    1 | 141 | 11.75 |   12.13 |  46.30\n    2 | 130 | 10.83 |   11.19 |  57.49\n    3 | 111 |  9.25 |    9.55 |  67.04\n    4 | 169 | 14.08 |   14.54 |  81.58\n    5 |  71 |  5.92 |    6.11 |  87.69\n    6 |  41 |  3.42 |    3.53 |  91.22\n    7 |  41 |  3.42 |    3.53 |  94.75\n    8 |  44 |  3.67 |    3.79 |  98.54\n    9 |  11 |  0.92 |    0.95 |  99.48\n   10 |   4 |  0.33 |    0.34 |  99.83\n   11 |   1 |  0.08 |    0.09 |  99.91\n   12 |   1 |  0.08 |    0.09 | 100.00\n <NA> |  38 |  3.17 |    <NA> |   <NA>\n\n\nVemos que los valores (labels) de cada categoría de las primeras variables que recodificamos no se corresponden con el nuevo valor. Para re-etiquetar valores usamos la función set_labels, de la librería sjlabelled\n\nproc_data$conf_gob <- set_labels(proc_data$conf_gob,\n            labels=c( \"Ninguna\"=0,\n                      \"Poca\"=1,\n                      \"Algo\"=2,\n                      \"Mucha\"=3))\n\nproc_data$conf_cong <- set_labels(proc_data$conf_cong,\n            labels=c( \"Ninguna\"=0,\n                      \"Poca\"=1,\n                      \"Algo\"=2,\n                      \"Mucha\"=3))\n\nproc_data$conf_jud <- set_labels(proc_data$conf_jud,\n            labels=c( \"Ninguna\"=0,\n                      \"Poca\"=1,\n                      \"Algo\"=2,\n                      \"Mucha\"=3))\n\nproc_data$conf_partpol <- set_labels(proc_data$conf_partpol,\n            labels=c( \"Ninguna\"=0,\n                      \"Poca\"=1,\n                      \"Algo\"=2,\n                      \"Mucha\"=3))\n\ny volvemos a revisar\n\nfrq(proc_data$conf_gob)\n\nConfianza: Gobierno (x) <numeric> \n# total N=1200 valid N=1181 mean=0.66 sd=0.80\n\nValue |   Label |   N | Raw % | Valid % | Cum. %\n------------------------------------------------\n    0 | Ninguna | 624 | 52.00 |   52.84 |  52.84\n    1 |    Poca | 358 | 29.83 |   30.31 |  83.15\n    2 |    Algo | 176 | 14.67 |   14.90 |  98.05\n    3 |   Mucha |  23 |  1.92 |    1.95 | 100.00\n <NA> |    <NA> |  19 |  1.58 |    <NA> |   <NA>\n\nfrq(proc_data$conf_cong)\n\nConfianza: Congreso (x) <numeric> \n# total N=1200 valid N=1178 mean=0.59 sd=0.71\n\nValue |   Label |   N | Raw % | Valid % | Cum. %\n------------------------------------------------\n    0 | Ninguna | 628 | 52.33 |   53.31 |  53.31\n    1 |    Poca | 408 | 34.00 |   34.63 |  87.95\n    2 |    Algo | 134 | 11.17 |   11.38 |  99.32\n    3 |   Mucha |   8 |  0.67 |    0.68 | 100.00\n <NA> |    <NA> |  22 |  1.83 |    <NA> |   <NA>\n\n\n\n4.2. Educación\n\n[reeduc_1] = REEDUC.1 Nivel de estudios alcanzado - Entrevistado (recodificado)\n\na. Descriptivo\n\nfrq(proc_data$reeduc_1)\n\nx <numeric> \n# total N=1200 valid N=1200 mean=5.05 sd=1.22\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n    1 |   8 |  0.67 |    0.67 |   0.67\n    2 |  53 |  4.42 |    4.42 |   5.08\n    3 |  36 |  3.00 |    3.00 |   8.08\n    4 | 161 | 13.42 |   13.42 |  21.50\n    5 | 643 | 53.58 |   53.58 |  75.08\n    6 | 109 |  9.08 |    9.08 |  84.17\n    7 | 190 | 15.83 |   15.83 | 100.00\n <NA> |   0 |  0.00 |    <NA> |   <NA>\n\n\nb. Recodificación\n\nVemos que no hay datos perdidos\nValores\n\nPara hacer más fácil el análisis, recodificamos en tres categorías (en este caso decisión arbitraria. Se debería tener una razón teórica para recodificar)\n1.  Analfabeto                                =   Educacion basica    =   1\n2   Básica incompleta                         =   Educacion basica    =   1\n3.  Básica completa                           =   Educacion basica    =   1\n4.  Secundaria, media, técnica incompleta     =   Educacion media     =   2\n5.  Secundaria, media, técnica completa       =   Educacion media     =   2\n6.  Superior incompleta                       =   Educacion superior  =   3\n7.  Superior completa                         =   Educacion superior  =   3\n\n\n# recodificacion usando funcion 'recode' de la libreria car\nproc_data$reeduc_1 <- car::recode(proc_data$reeduc_1, \"c(1,2,3)=1; c(4,5)=2; c(6,7)=3\")\n\nComprobar con un nuevo descriptivo:\n\nfrq(proc_data$reeduc_1)\n\nx <numeric> \n# total N=1200 valid N=1200 mean=2.17 sd=0.55\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n    1 |  97 |  8.08 |    8.08 |   8.08\n    2 | 804 | 67.00 |   67.00 |  75.08\n    3 | 299 | 24.92 |   24.92 | 100.00\n <NA> |   0 |  0.00 |    <NA> |   <NA>\n\n\nSe observa que los valores coinciden con la recodificación (los casos se acumulan entre las categorías 1 y 3), pero las etiquetas ahora no coinciden; se soluciona en el siguiente paso.\nc. Etiquetado\nPara re-etiquetar valores usamos la función set_labels, de la librería sjlabelled\n\nproc_data$reeduc_1 <- set_labels(proc_data$reeduc_1,\n            labels=c( \"Educacion basica\"=1,\n                      \"Educacion media\"=2,\n                      \"Educacion superior\"=3))\n\nLuego renombramos la variable con un nombre más sustantivo\n\nproc_data <- rename(proc_data,\"educacion\"=reeduc_1)\n\nAdemás de cambiar el nombre, queremos cambiar la etiqueta de la variable.\n\nget_label(proc_data$educacion)\n\nNULL\n\nproc_data$educacion <- set_label(x = proc_data$educacion,label = \"Educación\")\n\n\n\n\n4.3. Sexo\n\n[sexo] = SEXO Sexo\n\na. Descriptivo\n\nfrq(proc_data$sexo)\n\nx <numeric> \n# total N=1200 valid N=1200 mean=1.54 sd=0.50\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n    1 | 555 | 46.25 |   46.25 |  46.25\n    2 | 645 | 53.75 |   53.75 | 100.00\n <NA> |   0 |  0.00 |    <NA> |   <NA>\n\n\nb. Recodificación\nEn general esta variable no tiene problemas de casos perdidos ni de etiquetas, pero de todas maneras vamos a hacer un cambio de acuerdo a convenciones en análisis de datos, donde por lo general hombres tienen valor 0 y mujeres 1:\n\nproc_data$sexo <- car::recode(proc_data$sexo, \"1=0;2=1\")\n\nc. Etiquetado\nY ahora cambiamos las etiquetas de acuerdo a la recodificación anterior:\n\nproc_data$sexo <- set_labels(proc_data$sexo,\n            labels=c( \"Hombre\"=0,\n                      \"Mujer\"=1))\n\nTambién queremos cambiar la etiqueta de la variable.\n\nget_label(proc_data$sexo)\n\nNULL\n\nproc_data$sexo <- set_label(x = proc_data$sexo,label = \"Sexo\")\n\nRevisar con un nuevo descriptivo:\n\nfrq(proc_data$sexo)\n\nSexo (x) <numeric> \n# total N=1200 valid N=1200 mean=0.54 sd=0.50\n\nValue |  Label |   N | Raw % | Valid % | Cum. %\n-----------------------------------------------\n    0 | Hombre | 555 | 46.25 |   46.25 |  46.25\n    1 |  Mujer | 645 | 53.75 |   53.75 | 100.00\n <NA> |   <NA> |   0 |  0.00 |    <NA> |   <NA>\n\n\n\n\n4.4 Edad\n\n[edad] = EDAD Edad.\n\na. Descriptivo\n\nfrq(proc_data$edad)\n\nx <numeric> \n# total N=1200 valid N=1200 mean=44.49 sd=17.01\n\nValue |  N | Raw % | Valid % | Cum. %\n-------------------------------------\n   18 | 31 |  2.58 |    2.58 |   2.58\n   19 | 29 |  2.42 |    2.42 |   5.00\n   20 | 25 |  2.08 |    2.08 |   7.08\n   21 | 23 |  1.92 |    1.92 |   9.00\n   22 | 21 |  1.75 |    1.75 |  10.75\n   23 | 26 |  2.17 |    2.17 |  12.92\n   24 | 28 |  2.33 |    2.33 |  15.25\n   25 | 19 |  1.58 |    1.58 |  16.83\n   26 | 21 |  1.75 |    1.75 |  18.58\n   27 | 23 |  1.92 |    1.92 |  20.50\n   28 | 19 |  1.58 |    1.58 |  22.08\n   29 | 22 |  1.83 |    1.83 |  23.92\n   30 | 34 |  2.83 |    2.83 |  26.75\n   31 | 21 |  1.75 |    1.75 |  28.50\n   32 | 26 |  2.17 |    2.17 |  30.67\n   33 | 21 |  1.75 |    1.75 |  32.42\n   34 | 14 |  1.17 |    1.17 |  33.58\n   35 | 22 |  1.83 |    1.83 |  35.42\n   36 | 28 |  2.33 |    2.33 |  37.75\n   37 | 14 |  1.17 |    1.17 |  38.92\n   38 | 24 |  2.00 |    2.00 |  40.92\n   39 | 23 |  1.92 |    1.92 |  42.83\n   40 | 32 |  2.67 |    2.67 |  45.50\n   41 | 21 |  1.75 |    1.75 |  47.25\n   42 | 16 |  1.33 |    1.33 |  48.58\n   43 | 22 |  1.83 |    1.83 |  50.42\n   44 | 16 |  1.33 |    1.33 |  51.75\n   45 | 25 |  2.08 |    2.08 |  53.83\n   46 | 19 |  1.58 |    1.58 |  55.42\n   47 | 15 |  1.25 |    1.25 |  56.67\n   48 | 26 |  2.17 |    2.17 |  58.83\n   49 | 19 |  1.58 |    1.58 |  60.42\n   50 | 35 |  2.92 |    2.92 |  63.33\n   51 |  6 |  0.50 |    0.50 |  63.83\n   52 | 24 |  2.00 |    2.00 |  65.83\n   53 |  7 |  0.58 |    0.58 |  66.42\n   54 | 13 |  1.08 |    1.08 |  67.50\n   55 | 27 |  2.25 |    2.25 |  69.75\n   56 | 18 |  1.50 |    1.50 |  71.25\n   57 | 17 |  1.42 |    1.42 |  72.67\n   58 | 34 |  2.83 |    2.83 |  75.50\n   59 | 17 |  1.42 |    1.42 |  76.92\n   60 | 24 |  2.00 |    2.00 |  78.92\n   61 | 18 |  1.50 |    1.50 |  80.42\n   62 | 21 |  1.75 |    1.75 |  82.17\n   63 | 15 |  1.25 |    1.25 |  83.42\n   64 | 20 |  1.67 |    1.67 |  85.08\n   65 | 12 |  1.00 |    1.00 |  86.08\n   66 | 24 |  2.00 |    2.00 |  88.08\n   67 |  9 |  0.75 |    0.75 |  88.83\n   68 | 12 |  1.00 |    1.00 |  89.83\n   69 | 15 |  1.25 |    1.25 |  91.08\n   70 | 30 |  2.50 |    2.50 |  93.58\n   71 |  9 |  0.75 |    0.75 |  94.33\n   72 | 10 |  0.83 |    0.83 |  95.17\n   73 |  8 |  0.67 |    0.67 |  95.83\n   74 |  8 |  0.67 |    0.67 |  96.50\n   75 |  8 |  0.67 |    0.67 |  97.17\n   76 | 12 |  1.00 |    1.00 |  98.17\n   77 |  5 |  0.42 |    0.42 |  98.58\n   78 |  2 |  0.17 |    0.17 |  98.75\n   79 |  2 |  0.17 |    0.17 |  98.92\n   80 |  4 |  0.33 |    0.33 |  99.25\n   82 |  1 |  0.08 |    0.08 |  99.33\n   84 |  2 |  0.17 |    0.17 |  99.50\n   85 |  3 |  0.25 |    0.25 |  99.75\n   86 |  1 |  0.08 |    0.08 |  99.83\n   87 |  1 |  0.08 |    0.08 |  99.92\n   89 |  1 |  0.08 |    0.08 | 100.00\n <NA> |  0 |  0.00 |    <NA> |   <NA>\n\n\nb. Recodificación: no es necesario en este caso\nc. Etiquetado\nCambio la etiqueta de la variable.\n\nget_label(proc_data$edad)\n\nNULL\n\nproc_data$edad <- set_label(x = proc_data$edad,label = \"Edad\")"
  },
  {
    "objectID": "resource/02-resource.html#generación-de-base-de-datos-procesada-para-el-análisis",
    "href": "resource/02-resource.html#generación-de-base-de-datos-procesada-para-el-análisis",
    "title": "Práctica 2. Operacionalización de variables",
    "section": "5. Generación de base de datos procesada para el análisis",
    "text": "5. Generación de base de datos procesada para el análisis\nAntes de guardar la base procesada, revisamos nuevamente todas las variables con una tabla descriptiva general mediante la función stargazer (de la librería homónima)\nPrimero vamos a reformatear el objeto proc_data como base de datos (as.data.frame), paso necesario para que sea reconocido como tal por stargazer\n\nproc_data <-as.data.frame(proc_data)\nstargazer(proc_data, type=\"text\")\n\n\n===========================================\nStatistic      N    Mean   St. Dev. Min Max\n-------------------------------------------\nconf_gob     1,181  0.660   0.800    0   3 \nconf_cong    1,178  0.594   0.714    0   3 \nconf_jud     1,186  0.717   0.789    0   3 \nconf_partpol 1,178  0.451   0.673    0   3 \neducacion    1,200  2.168   0.549    1   3 \nsexo         1,200  0.537   0.499    0   1 \nedad         1,200 44.491   17.008  18  89 \nidenpa       1,200 152.000  0.000   152 152\nconf_inst    1,162  2.420   2.489    0  12 \n-------------------------------------------\n\n\n\nSi se desea modificar las columnas que aparecen en la tabla se puede ocupar la opción summary.stat, donde se pueden especificar:\n\n“max” maximum\n“mean” mean\n“median” median\n“min” minimum\n“n” number of observations\n“p25” 25th percentile\n“p75” 75th percentile\n“sd” standard deviation\n\nPor ejemplo, si quiero una tabla solo con promedio, n, sd y p75: stargazer(data, type=\"text\", summary.stat = c(\"mean\", \"n\", \"sd\", \"p75\"))\n\n\nGuardar base de datos procesada: en carpeta local La ruta hacia su carpeta local si está trabajando en windows debería ser algo como “C:/Users/Lenovo/Clases/y aquí nombre del archivo a grabar\n\nEl comando para guardar es save:\n\nsave(proc_data,file = \"[ruta hacia carpeta local en su computador]/ELSOC_ess_merit2016.RData\")\n\nEn este caso, seguimos una estructura de carpetas de datos, separando en una carpeta los datos originales, y en otra (proc) los datos procesados:\n\nsave(proc_data,file = \"files/data/latinobarometro_proc.RData\")\n\n\nDe rutas, estructura de carpetas y otros \n\nEncontrando la ruta a carpeta local: lo más fácil es crear la carpeta donde se desean guardar los datos desde el administrador de archivos del computador. Luego, posicionarse con el cursor sobre la carpeta y seleccionar “Propiedades”, en la ventana emergente debería aparecer la ruta hacia la carpeta en “Ubicación”. Copiar esa ruta y agregar al final el nombre de la carpeta (separada por slash)\nSobre los “slashes” (\\ o /): en la ruta las carpetas y el archivo final aparecen separados por slashes, que según el sistema utilizado pueden ser slash (/) o backslash (\\). En R por defecto se usa slash, pero en Windows backslash, por lo que si se usa Windows hay que reemplazarlos por backslash o también puede ser por un doble slash (//).\nPor temas de compatibilidad general, en las rutas se recomienda evitar tildes, eñes, espacios, mayúsculas y guiones bajos (_).\nEstructura de carpetas: para mantener el orden se sugiere seguir un protocolo de estructura de carpetas de proyecto, para lo que recomendamos el protocolo IPO, y que se adapta al flujo de trabajo presentado al principio de este práctico. Básicamente son tres carpetas: input, procesamiento, output. En la carpeta input crear la subcarpeta data-orig para guardar datos originales, y data-proc para los procesados. En procesamiento se guardan los archivos de código y en output las tablas y los gráficos."
  },
  {
    "objectID": "resource/02-resource.html#descriptivos-básicos-de-las-variables",
    "href": "resource/02-resource.html#descriptivos-básicos-de-las-variables",
    "title": "Práctica 2. Operacionalización de variables",
    "section": "Descriptivos básicos de las variables",
    "text": "Descriptivos básicos de las variables\nPodemos conocer ciertas medidas de tendencia central utilizando algunas funciones de dplyr\n\nMedia por grupos\n\nproc_data %>% dplyr::group_by(sexo) %>% summarise(mean(conf_inst, na.rm=TRUE))\n\n# A tibble: 2 × 2\n   sexo `mean(conf_inst, na.rm = TRUE)`\n  <dbl>                           <dbl>\n1     0                            2.48\n2     1                            2.36\n\n\n\nproc_data %>% dplyr::group_by(educacion) %>% summarise(mean(conf_inst, na.rm=TRUE))\n\n# A tibble: 3 × 2\n  educacion `mean(conf_inst, na.rm = TRUE)`\n      <dbl>                           <dbl>\n1         1                            2.96\n2         2                            2.38\n3         3                            2.36\n\n\n\n\nRepresentación\n\nlibrary(sjPlot)\n\nInstall package \"strengejacke\" from GitHub (`devtools::install_github(\"strengejacke/strengejacke\")`) to load all sj-packages at once!\n\nsjt.xtab(proc_data$educacion, proc_data$conf_inst, encoding = \"UTF-8\")\n\n\n\n \n Educación\n Confianza eninstituciones\n Total\n \n \n\n 0\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n 10\n 11\n 12\n \n \n \nEducacion basica\n30\n11\n6\n6\n12\n6\n4\n4\n7\n3\n0\n0\n1\n90 \n\n \n \nEducacion media\n268\n95\n83\n79\n121\n45\n24\n29\n28\n3\n4\n1\n0\n780 \n\n \n \nEducacion superior\n99\n35\n41\n26\n36\n20\n13\n8\n9\n5\n0\n0\n0\n292 \n\n \n \nTotal\n397\n141\n130\n111\n169\n71\n41\n41\n44\n11\n4\n1\n1\n1162 \n\nχ2=37.850 · df=24 · Cramer's V=0.128 · Fisher's p=0.144"
  },
  {
    "objectID": "resource/03-resource.html",
    "href": "resource/03-resource.html",
    "title": "Práctica 3. Visualización de datos",
    "section": "",
    "text": "Esta práctica asume como base el desarrollo de la Práctica anterior, a la cual se hará referencia permanente.\nEn la Práctica anterior se desarrolló un código de preparación de datos que generó una base de datos procesada para el análisis. En esta Práctica comenzamos con el segundo momento de procesamiento de datos, que es el análisis propiamente tal. El análisis se divide en descripción de variables y contraste de hipótesis. En esta práctica nos enfocaremos en la primera fase, que llega hasta el punto 3 del código de análisis:\n\nAl igual que el Código de Preparación, el Código de Análisis posee una estructura definida. En este caso son 4 partes, donde las primeras son similares al código de preparación:\n\nIdentificación y descripción general: Título, autor(es), fecha, información breve sobre el contenido del documento\nLibrerías principales (de R) a utilizar en el análisis\nDatos (que provienen de los preparados en la fase anterior)\nDescripción de variables\n\nTabla general de variables para la sección metodológica del reporte\nExploración descriptiva de relaciones entre variables\n\nContraste de hipótesis / inferencia estadística según la técnica que corresponda\n\nAl final de esta práctica la idea es que cada un_ pueda avanzar hasta el punto 3 del Código de Análisis. El punto 4 (contraste de hipótesis) se desarrollará más adelante en este curso con énfasis en la técnica de regresión."
  },
  {
    "objectID": "resource/03-resource.html#librerías",
    "href": "resource/03-resource.html#librerías",
    "title": "Práctica 3. Visualización de datos",
    "section": "1. Librerías",
    "text": "1. Librerías\n\npacman::p_load(sjlabelled,\n               dplyr, #Manipulacion de datos\n              stargazer, #Tablas\n              sjmisc, # Tablas\n              summarytools, # Tablas\n              kableExtra, #Tablas\n              sjPlot, #Tablas y gráficos\n              corrplot, # Correlaciones\n              sessioninfo, # Información de la sesión de trabajo\n              ggplot2) # Para la mayoría de los gráficos"
  },
  {
    "objectID": "resource/03-resource.html#cargar-base-de-datos",
    "href": "resource/03-resource.html#cargar-base-de-datos",
    "title": "Práctica 3. Visualización de datos",
    "section": "2. Cargar base de datos",
    "text": "2. Cargar base de datos\nVamos a cargar la base de datos latinobarometro_proc.Rdata, que generamos durante la práctica anterior. Se puede llamar desde el directorio en que se guardó anteriormente dando la ruta completa:\n\nload(\"ruta-hacia-carpeta-local/latinobarometro_proc.RData\") #Cargar base de datos\n\nO también para esta práctica la podemos llamar directamente desde nuestro sitio web:\n\nload(url(\"https://github.com/Kevin-carrasco/metod1-MCS/raw/main/files/data/latinobarometro_proc.RData\")) #Cargar base de datos\n\n\nExploración inicial general de la base de datos\n\n\nnames(proc_data) # Muestra los nombres de las variables de la base de datos\n\n[1] \"conf_gob\"     \"conf_cong\"    \"conf_jud\"     \"conf_partpol\" \"educacion\"   \n[6] \"sexo\"         \"edad\"         \"idenpa\"       \"conf_inst\"   \n\ndim(proc_data) # Dimensiones\n\n[1] 1200    9\n\n\nEn el caso de esta base, 1200 casos y 9 variables\nRecordando el contenido de cada variable preparada en la práctica anterior:\n\n[conf_gob] = Confianza en el gobierno.\n[conf_cong] = Confianza en el congreso.\n[conf_jud] = Confianza en el poder judicial.\n[conf_partpol] = Confianza en los partidos políticos.\n[conf_inst] = Indice sumativo de confianza en instituciones políticas.\n[educacion] = Nivel educacional(1 = Educacion básica, 2 = Educacion media, 3 = superior)\n[sexo] = Sexo (O = Hombre; 1 = Mujer)\n[edad] = ¿Cuáles su edad?"
  },
  {
    "objectID": "resource/03-resource.html#descripción-de-variables",
    "href": "resource/03-resource.html#descripción-de-variables",
    "title": "Práctica 3. Visualización de datos",
    "section": "3. Descripción de variables",
    "text": "3. Descripción de variables\nLos resultados referidos a descripción de variables se presentan en dos momentos del reporte de investigación:\n\nen la sección de metodología, cuando se presentan las variables del estudio en una tabla descriptiva de variables.\nen la sección de análisis, que en general comienza con una exploración de asociaciones entre variables, también conocido como análisis descriptivo.\n\n\n3.1 Tabla descriptiva de variables para sección metodológica\nA continuación se presentan dos opciones de generar esta tabla descriptiva de variables con distintas librerías de R.\na. Tabla descriptiva con stargazerstargazer\nLa función stargazer (de la librería del mismo nombre) permitirá mostrar los principales estadísticos descriptivos univariados de las variables: medidas de tendencia central (media), de dispersión (desviación estándar) y posición (mínimo, máximo, percentiles).\n\nstargazer(proc_data,type = \"text\")\n\n\n===========================================\nStatistic      N    Mean   St. Dev. Min Max\n-------------------------------------------\nconf_gob     1,181  0.660   0.800    0   3 \nconf_cong    1,178  0.594   0.714    0   3 \nconf_jud     1,186  0.717   0.789    0   3 \nconf_partpol 1,178  0.451   0.673    0   3 \neducacion    1,200  2.168   0.549    1   3 \nsexo         1,200  0.537   0.499    0   1 \nedad         1,200 44.491   17.008  18  89 \nidenpa       1,200 152.000  0.000   152 152\nconf_inst    1,162  2.420   2.489    0  12 \n-------------------------------------------\n\n\nAlgunas observaciones sobre esta tabla:\n\nLa opción type=\"text\" permite que podamos ver los resultados directamente en la consola, de manera bastante rudimentaria. Con otras opciones que veremos más adelante se puede estilizar para su publicación.\nUna distinción relevante a considerar cuando se describen variables es si estas son categóricas o continuas. La definición de si una variables es tratada como categórica o continua es algo que hace el/la autor/a del reporte, sin embargo hay variables nominales como sexo que claramente corresponden a categóricas, y por lo tanto no corresponde hacer un promedio entre ambas. Sin embargo, como esta variable está codificada 0 (hombre) y 1 (mujer), en este caso lo que indica el valor de la columna promedio (Mean=0.537) es la proporción de mujeres vs hombres. En otras palabras, hay un 54% de mujeres y 46% de hombres en la muestra.\n\nb. Tablas descriptivas con descr, librería sjmiscsjmisc::descr\nLa opción básica de descr es la siguiente:\n\nsjmisc::descr(proc_data)\n\n\n## Basic descriptive statistics\n\n          var    type                         label    n NA.prc   mean    sd\n     conf_gob numeric           Confianza: Gobierno 1181   1.58   0.66  0.80\n    conf_cong numeric           Confianza: Congreso 1178   1.83   0.59  0.71\n     conf_jud numeric     Confianza: Poder judicial 1186   1.17   0.72  0.79\n conf_partpol numeric Confianza: Partidos politicos 1178   1.83   0.45  0.67\n    educacion numeric                     Educación 1200   0.00   2.17  0.55\n         sexo numeric                          Sexo 1200   0.00   0.54  0.50\n         edad numeric                          Edad 1200   0.00  44.49 17.01\n       idenpa numeric                        idenpa 1200   0.00 152.00  0.00\n    conf_inst numeric    Confianza en instituciones 1162   3.17   2.42  2.49\n   se  md trimmed       range iqr  skew\n 0.02   0    0.55     3 (0-3)   1  0.92\n 0.02   0    0.49     3 (0-3)   1  0.89\n 0.02   1    0.62     3 (0-3)   1  0.84\n 0.02   0    0.32     3 (0-3)   1  1.33\n 0.02   2    2.19     2 (1-3)   0  0.07\n 0.01   1    0.55     1 (0-1)   1 -0.15\n 0.49  43   43.96  71 (18-89)  28  0.22\n 0.00 152  152.00 0 (152-152)   0   NaN\n 0.07   2    2.07   12 (0-12)   4  0.88\n\n\nEn este caso utilizamos la forma librería::función (sjmisc::descr), ya que la función descr también existe en otras librerías y así nos aseguramos que la función utilizada es de esa librería específica.\nSeleccionamos algunas columnas específicas con información más relevante con la opción show. Además, agregamos la función kable para obtener una tabla que luego sea fácilmente publicable en distintos formatos (a profundizar en ejercicios posteriores):\n\nsjmisc::descr(proc_data,\n      show = c(\"label\",\"range\", \"mean\", \"sd\", \"NA.prc\", \"n\"))%>%\n      kable(.,\"markdown\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvar\nlabel\nn\nNA.prc\nmean\nsd\nrange\n\n\n\n\n2\nconf_gob\nConfianza: Gobierno\n1181\n1.583333\n0.6596105\n0.7999806\n3 (0-3)\n\n\n1\nconf_cong\nConfianza: Congreso\n1178\n1.833333\n0.5942275\n0.7140065\n3 (0-3)\n\n\n4\nconf_jud\nConfianza: Poder judicial\n1186\n1.166667\n0.7166948\n0.7885304\n3 (0-3)\n\n\n5\nconf_partpol\nConfianza: Partidos politicos\n1178\n1.833333\n0.4507640\n0.6733451\n3 (0-3)\n\n\n7\neducacion\nEducación\n1200\n0.000000\n2.1683333\n0.5494684\n2 (1-3)\n\n\n9\nsexo\nSexo\n1200\n0.000000\n0.5375000\n0.4987996\n1 (0-1)\n\n\n6\nedad\nEdad\n1200\n0.000000\n44.4908333\n17.0076738\n71 (18-89)\n\n\n8\nidenpa\nidenpa\n1200\n0.000000\n152.0000000\n0.0000000\n0 (152-152)\n\n\n3\nconf_inst\nConfianza en instituciones\n1162\n3.166667\n2.4199656\n2.4887441\n12 (0-12)\n\n\n\n\n\nc. Tabla descriptiva con summarytools::dfSummarysummarytools::dfSummary\nEsta tercera opción nos ofrece una tabla aún más detallada, con gráficos para cada variable, las frecuencias para cada valor, y las etiquetas de las variables, por lo que es muy recomendable.\nSe específica de la siguiente manera:\n\nsummarytools::dfSummary(proc_data, plain.ascii = FALSE)\n\n### Data Frame Summary  \n#### proc_data  \n**Dimensions:** 1200 x 9  \n**Duplicates:** 276  \n\n-----------------------------------------------------------------------------------------------------------------------------------------------\nNo   Variable        Label                           Stats / Values           Freqs (% of Valid)    Graph                  Valid      Missing  \n---- --------------- ------------------------------- ------------------------ --------------------- ---------------------- ---------- ---------\n1    conf_gob\\       Confianza: Gobierno             Mean (sd) : 0.7 (0.8)\\   0 : 624 (52.8%)\\      IIIIIIIIII \\           1181\\      19\\      \n     [numeric]                                       min < med < max:\\        1 : 358 (30.3%)\\      IIIIII \\               (98.4%)    (1.6%)   \n                                                     0 < 0 < 3\\               2 : 176 (14.9%)\\      II \\                                       \n                                                     IQR (CV) : 1 (1.2)       3 :  23 ( 1.9%)                                                  \n\n2    conf_cong\\      Confianza: Congreso             Mean (sd) : 0.6 (0.7)\\   0 : 628 (53.3%)\\      IIIIIIIIII \\           1178\\      22\\      \n     [numeric]                                       min < med < max:\\        1 : 408 (34.6%)\\      IIIIII \\               (98.2%)    (1.8%)   \n                                                     0 < 0 < 3\\               2 : 134 (11.4%)\\      II \\                                       \n                                                     IQR (CV) : 1 (1.2)       3 :   8 ( 0.7%)                                                  \n\n3    conf_jud\\       Confianza: Poder judicial       Mean (sd) : 0.7 (0.8)\\   0 : 556 (46.9%)\\      IIIIIIIII \\            1186\\      14\\      \n     [numeric]                                       min < med < max:\\        1 : 438 (36.9%)\\      IIIIIII \\              (98.8%)    (1.2%)   \n                                                     0 < 1 < 3\\               2 : 164 (13.8%)\\      II \\                                       \n                                                     IQR (CV) : 1 (1.1)       3 :  28 ( 2.4%)                                                  \n\n4    conf_partpol\\   Confianza: Partidos politicos   Mean (sd) : 0.5 (0.7)\\   0 : 760 (64.5%)\\      IIIIIIIIIIII \\         1178\\      22\\      \n     [numeric]                                       min < med < max:\\        1 : 313 (26.6%)\\      IIIII \\                (98.2%)    (1.8%)   \n                                                     0 < 0 < 3\\               2 :  97 ( 8.2%)\\      I \\                                        \n                                                     IQR (CV) : 1 (1.5)       3 :   8 ( 0.7%)                                                  \n\n5    educacion\\      Educación                       Mean (sd) : 2.2 (0.5)\\   1 :  97 ( 8.1%)\\      I \\                    1200\\      0\\       \n     [numeric]                                       min < med < max:\\        2 : 804 (67.0%)\\      IIIIIIIIIIIII \\        (100.0%)   (0.0%)   \n                                                     1 < 2 < 3\\               3 : 299 (24.9%)       IIII                                       \n                                                     IQR (CV) : 0 (0.3)                                                                        \n\n6    sexo\\           Sexo                            Min  : 0\\                0 : 555 (46.2%)\\      IIIIIIIII \\            1200\\      0\\       \n     [numeric]                                       Mean : 0.5\\              1 : 645 (53.8%)       IIIIIIIIII             (100.0%)   (0.0%)   \n                                                     Max  : 1                                                                                  \n\n7    edad\\           Edad                            Mean (sd) : 44.5 (17)\\   69 distinct values    :\\                     1200\\      0\\       \n     [numeric]                                       min < med < max:\\                              : : . . . .\\           (100.0%)   (0.0%)   \n                                                     18 < 43 < 89\\                                  : : : : : : : .\\                           \n                                                     IQR (CV) : 28 (0.4)                            : : : : : : : :\\                           \n                                                                                                    : : : : : : : : :                          \n\n8    idenpa\\                                         1 distinct value         152 : 1200 (100.0%)   IIIIIIIIIIIIIIIIIIII   1200\\      0\\       \n     [numeric]                                                                                                             (100.0%)   (0.0%)   \n\n9    conf_inst\\      Confianza en instituciones      Mean (sd) : 2.4 (2.5)\\   13 distinct values    :\\                     1162\\      38\\      \n     [numeric]                                       min < med < max:\\                              :\\                     (96.8%)    (3.2%)   \n                                                     0 < 2 < 12\\                                    :\\                                         \n                                                     IQR (CV) : 4 (1)                               : \\ \\ \\ \\ .\\                               \n                                                                                                    : : : : : . .                              \n-----------------------------------------------------------------------------------------------------------------------------------------------\n\n\nEs muy ancha para visualizar bien en la consola de R, pero en su versión más definitiva de publicación se verá así:\n\nview(dfSummary(proc_data, headings=FALSE))\n\n\n\n\n\n\n  \n    \n      No\n      Variable\n      Label\n      Stats / Values\n      Freqs (% of Valid)\n      Graph\n      Valid\n      Missing\n    \n  \n  \n    \n      1\n      conf_gob\n[numeric]\n      Confianza: Gobierno\n      Mean (sd) : 0.7 (0.8)min ≤ med ≤ max:0 ≤ 0 ≤ 3IQR (CV) : 1 (1.2)\n      0:624(52.8%)1:358(30.3%)2:176(14.9%)3:23(1.9%)\n      \n      1181\n(98.4%)\n      19\n(1.6%)\n    \n    \n      2\n      conf_cong\n[numeric]\n      Confianza: Congreso\n      Mean (sd) : 0.6 (0.7)min ≤ med ≤ max:0 ≤ 0 ≤ 3IQR (CV) : 1 (1.2)\n      0:628(53.3%)1:408(34.6%)2:134(11.4%)3:8(0.7%)\n      \n      1178\n(98.2%)\n      22\n(1.8%)\n    \n    \n      3\n      conf_jud\n[numeric]\n      Confianza: Poder judicial\n      Mean (sd) : 0.7 (0.8)min ≤ med ≤ max:0 ≤ 1 ≤ 3IQR (CV) : 1 (1.1)\n      0:556(46.9%)1:438(36.9%)2:164(13.8%)3:28(2.4%)\n      \n      1186\n(98.8%)\n      14\n(1.2%)\n    \n    \n      4\n      conf_partpol\n[numeric]\n      Confianza: Partidos politicos\n      Mean (sd) : 0.5 (0.7)min ≤ med ≤ max:0 ≤ 0 ≤ 3IQR (CV) : 1 (1.5)\n      0:760(64.5%)1:313(26.6%)2:97(8.2%)3:8(0.7%)\n      \n      1178\n(98.2%)\n      22\n(1.8%)\n    \n    \n      5\n      educacion\n[numeric]\n      Educación\n      Mean (sd) : 2.2 (0.5)min ≤ med ≤ max:1 ≤ 2 ≤ 3IQR (CV) : 0 (0.3)\n      1:97(8.1%)2:804(67.0%)3:299(24.9%)\n      \n      1200\n(100.0%)\n      0\n(0.0%)\n    \n    \n      6\n      sexo\n[numeric]\n      Sexo\n      Min  : 0Mean : 0.5Max  : 1\n      0:555(46.2%)1:645(53.8%)\n      \n      1200\n(100.0%)\n      0\n(0.0%)\n    \n    \n      7\n      edad\n[numeric]\n      Edad\n      Mean (sd) : 44.5 (17)min ≤ med ≤ max:18 ≤ 43 ≤ 89IQR (CV) : 28 (0.4)\n      69 distinct values\n      \n      1200\n(100.0%)\n      0\n(0.0%)\n    \n    \n      8\n      idenpa\n[numeric]\n      \n      1 distinct value\n      152:1200(100.0%)\n      \n      1200\n(100.0%)\n      0\n(0.0%)\n    \n    \n      9\n      conf_inst\n[numeric]\n      Confianza en instituciones\n      Mean (sd) : 2.4 (2.5)min ≤ med ≤ max:0 ≤ 2 ≤ 12IQR (CV) : 4 (1)\n      13 distinct values\n      \n      1162\n(96.8%)\n      38\n(3.2%)\n    \n  \n\nGenerated by summarytools 1.0.1 (R version 4.2.3)2023-04-28\n\n\n\n\nNota sobre casos perdidos (NAs) na.omit(data)\nHasta ahora hemos mantenido los casos perdidos en la base de datos, ya que son importantes de reportar en la tabla general de variables. Sin embargo, de aquí en adelante se recomienda trabajar solo con casos completos, es decir, sacar los casos perdidos. El quitar los casos perdidos de una base de datos es muy simple con la función na.omit, pero para tomar precauciones y asegurarse que funciona se recomienda el siguiente procedimiento:\n\nrespaldar la base de datos original en el espacio de trabajo (por si queremos en adelante realizar algún análisis referido a casos perdidos), la dejaremos con el nombre proc_data_original.\ncontamos el número de casos con el comando dim\ncontamos el número de casos perdidos con sum(is.na(proc_data))\nborramos los casos perdidos con proc_data <-na.omit(proc_data)\ncontamos nuevamente con dim para asegurarnos que se borraron\ny por temas de funcionamiento de R, al realizar la operación de sacar casos perdidos, se borra toda la información de las etiquetas (labels), así que las recuperamos de la base original con el comando copy_labels, de la librería sjlabelled.\n\n\nproc_data_original <-proc_data\ndim(proc_data)\n\n[1] 1200    9\n\nsum(is.na(proc_data))\n\n[1] 115\n\nproc_data <-na.omit(proc_data)\ndim(proc_data)\n\n[1] 1162    9\n\nproc_data <-sjlabelled::copy_labels(proc_data,proc_data_original)\n\n\n\n\n3.2 Exploración de asociación entre variables\nDado que las hipótesis de investigación corresponden a asociación entre variables, antes de realizar el contraste de hipótesis se suele presentar un análisis descriptivo que explora las asociaciones entre variables.\nLa forma de explorar las asociaciones entre variables dependen de la naturaleza de las variables que se asocian:\n\nVariables categóricas: tabla de contingencia\nVariable categórica y continua: tabla de promedios por cada categoría\n\nEn esta sección también es muy relevante la visualización de datos mediante gráficos, por lo que incluiremos algunos.\nEl uso tanto de tablas como de gráficos en el reporte queda a discreción del/a autor/a. La pregunta que orienta esta decisión es: ¿Me permite enriquecer la discusión de los resultados en relación a las hipótesis planteadas?\n\nTablas de contingencia para variables categóricas\nPara tablas de contingencia categóricas utilizaremos la función sjt.xtab, de la librería sjPlot. Veamos primero una especificación simple: sjPlot::sjt.xtab\n\nsjt.xtab(proc_data$educacion, proc_data$sexo)\n\n\n\n \n Educación\n Sexo\n Total\n \n \n\n Hombre\n Mujer\n \n \n \nEducacion basica\n40\n50\n90 \n\n \n \nEducacion media\n347\n433\n780 \n\n \n \nEducacion superior\n158\n134\n292 \n\n \n \nTotal\n545\n617\n1162 \n\nχ2=8.136 · df=2 · Cramer's V=0.084 · p=0.017 \n\n \n\n\n\nAl ejecutar el comando, el resultado aparece automáticamente en el visor de RStudio. A esta tabla podemos también agregar porcentajes de filas y/o columnas, según sea lo más relevante analizar. En general se recomienda agregar solo un porcentaje, de otra manera la tabla se satura de información. Además, vamos a quitar el pie de la tabla (conviene dejarlo solo si hay hipótesis asociadas al cruce simple entre las dos variables).\n\nsjt.xtab(proc_data$educacion, proc_data$sexo,\n        show.col.prc=TRUE,\n        show.summary=FALSE,\n        encoding = \"UTF-8\"\n)\n\n\n\n \n Educación\n Sexo\n Total\n \n \n\n Hombre\n Mujer\n \n \n \nEducacion basica\n407.3 %\n508.1 %\n907.7 % \n\n \n \nEducacion media\n34763.7 %\n43370.2 %\n78067.1 % \n\n \n \nEducacion superior\n15829 %\n13421.7 %\n29225.1 % \n\n \n \nTotal\n545100 %\n617100 %\n1162100 % \n\n \n\n\n\n\n\nTablas de promedio de variable continua por una categóricas\nEn ejemplo vamos a explorar datos de nuestra variable de confianza en instituciones conf_inst por los niveles educacionales educacion.\nUna forma rápida de explorar esto es mediante la función tapply, que nos entrega de manera simple el promedio de una variable por otra:\n\ntapply(proc_data$conf_inst, proc_data$educacion, mean)\n\n       1        2        3 \n2.955556 2.379487 2.363014 \n\n\nAquí vemos en promedio de conf_inst para cada uno de los 3 niveles de la variable educación educacion. Si se estima conveniente este tipo de cruces se puede representar también en una tabla con más opciones de información y también de publicación. Para esto utilizaremos una función algo más compleja de la librería dplyr.dplyr Esta librería permite aplicar una serie de funciones concatenadas y enlazadas mediante el operador %>%. El sentido de cada función aparece comentado abajo:\n\nproc_data %>% # se especifica la base de datos\n  select(conf_inst,educacion) %>% # se seleccionan las variables\n  dplyr::group_by(Educación=sjlabelled::as_label(educacion)) %>% # se agrupan por la variable categórica y se usan sus etiquetas con as_label\n  dplyr::summarise(Obs.=n(),Promedio=mean(conf_inst),SD=sd(conf_inst)) %>% # se agregan las operaciones a presentar en la tabla\n  kable(, format = \"markdown\") # se genera la tabla\n\n\n\n\nEducación\nObs.\nPromedio\nSD\n\n\n\n\nEducacion basica\n90\n2.955556\n3.035043\n\n\nEducacion media\n780\n2.379487\n2.436266\n\n\nEducacion superior\n292\n2.363014\n2.430845\n\n\n\n\n\nEsta asociación también se puede representar de manera más simple con un gráfico, en este caso de cajas o boxplot mediante la función plot_grpfrq de sjPlot:sjPlot::plot_grpfrq\n\ngraph <- plot_grpfrq(proc_data$conf_inst,proc_data$educacion,\n            type = \"box\")\n\ngraph\n\n\n\n# y lo podemos guardar:\n\nggsave(graph, file=\"files/img/graph.png\")\n\nSaving 7 x 5 in image\n\n\nDe manera alternativa, podemos seguir explorando nuestros datos con otros gráficos\nPara variables univariadas:\n\ngraph1 <- sjPlot::plot_frq(proc_data$conf_inst,\n                 title = \"Confianza en instituciones\",\n                 type = \"bar\",\n                 axis.title = \"Confianza en institucines\",\n                 geom.colors = \"coral\") +\n  theme_bw()\n\ngraph1\n\n\n\n# y lo podemos guardar:\n\nggsave(graph1, file=\"files/img/graph1.png\")\n\nSaving 7 x 5 in image\n\n\nPara varias variables univariadas:\n\ngraph2 <- sjPlot::plot_stackfrq(dplyr::select(proc_data, conf_gob,\n                                 conf_cong,\n                                 conf_jud,\n                                 conf_partpol),\n                                 geom.colors = c(\"coral\", \"cadetblue\"),\n                                 title = \"Confianza en instituciones políticas\") +\n  theme(legend.position=\"bottom\")\n\nWarning in sj.setGeomColors(baseplot, geom.colors, length(legend.labels), : Too\nless colors provided for plot. Using default color palette.\n\ngraph2\n\n\n\n# Guardamos\n\nggsave(graph2, file=\"files/img/graph2.png\")\n\nSaving 7 x 5 in image\n\n\nPara asociación de dos variables:\n\nproc_data$sexo <- as_factor(proc_data$sexo)\n\ngraph3 <- proc_data %>% ggplot(aes(x = conf_inst, fill = sexo)) + \n  geom_bar() +\n  xlab(\"Confianza en instituciones\") +\n  ylab(\"Cantidad\") + \n  labs(fill=\"Sexo\")+\n  scale_fill_discrete(labels = c('Hombre','Mujer'))\n\ngraph3\n\n\n\n# Guardamos\n\nggsave(graph3, file=\"files/img/graph3.png\")\n\nSaving 7 x 5 in image\n\n\nPara variables continuas\n\ngraph4 <- ggplot(proc_data, aes(x = as.numeric(edad))) +\n  geom_histogram(binwidth=0.6, colour=\"black\", fill=\"yellow\") +\n  theme_bw() +\n  xlab(\"Edad\") +\n  ylab(\"Cantidad\")\n\ngraph4 \n\n\n\n# Guardamos\n\nggsave(graph4, file=\"files/img/graph4.png\")\n\nSaving 7 x 5 in image"
  },
  {
    "objectID": "resource/index.html",
    "href": "resource/index.html",
    "title": "Recursos",
    "section": "",
    "text": "En esta sección se presentan una serie de recursos como ejemplos de investigaciones, construcción de instrumentos, muestreo, análisis y reporte.\n[en construcción]"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Planificación",
    "section": "",
    "text": "Los dos componentes centrales del curso son las clases teóricas y las actividades prácticas. Las clases se realizarán los días Viernes 09:00 a 10:50 en sala 329\n\nClases ( ): Lecturas, documentos de presentación y video (en caso que la sesión sea grabada)\nPrácticas y evaluaciones (): Actividades prácticas a desarrollar durante la semana.\nLecturas (): Llegar a la clase con los textos leídos.\n\n\n\n\n\n Clases\n Prácticas y evaluaciones\n Lecturas y material adicional\n\n\n\n\n Marzo \n\n\n\n\n\nViernes 17\n00. Presentación e 01. introducción\n1. Aproximación inicial a R\n- Leer detalladamente programa del curso\n\n\n\n\nUNIDAD 1: Estadística descriptiva\n\n\n\nViernes 24\n2.Operacionalización de variables \n2.Operacionalización de variables\n- Wickham & Grolemund, (2017). cap. 1 Introducción \n\n\nViernes 31\n3. Visualización de datos\n-\n- Wickham & Grolemund, (2017). cap. 2 Explorar\n\n\n Abril \n\n\n\n\n\nViernes 07\nViernes santo\n\n\n\n\nViernes 14\n1° semana presencial\n\n\n\n\nViernes 21\n\nEvaluación\n\n\n\n\n\n\nUNIDAD 2: Estadística Correlacional\n\n\n\nViernes 28\n4. Introducción a la inferencia estadística\n\n\n\n\n Mayo \n\n\n\n\n\nViernes 05\n1° semana de pausa reflexiva\n\n\n\n\nViernes 12\n5. Correlación\n\n\n\n\nViernes 19\n6. Índices y análisis factorial\n\n\n\n\nViernes 26\n2° semana presencial\n\n\n\n\n\n\n\nUNIDAD 3: Regresión lineal y regresión logística\n\n\n\n Junio \n\n\n\n\n\nViernes 02\n7. Regresión lineal de mínimos cuadrados\n\n\n\n\nViernes 09\n2° semana de pausa reflexiva\n\n\n\n\nViernes 16\n**8. Regresión logística binaria: interpretación de coeficientes y cálculo de probabilidades\n\n\n\n\nViernes 23\n9. Estimación y visualización de regresiones en R\n\n\n\n\nViernes 30\n10. Supuestos de regresión\n\n\n\n\n Julio \n\n\n\n\n\nViernes 07\n3° semana presencial\n\n\n\n\nViernes 14\n\nEvaluación"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Programa",
    "section": "",
    "text": "Juan Carlos Castillo, Pablo Perez Ahumada & Kevin Carrasco\n   Departamento de Sociología FACSO - sala 328\n   juancastillov@uchile.cl, pabloperez@uchile.cl, kevin.carrasco@ug.uchile.cl\n   juankcastillo, pablo_perez_a, kevincarrascoq1\n   Schedule an appointment\n\n\n\n\n\n   Viernes\n   Marzo 17–Julio 07, 2023\n   09:00-10:50 AM\n   Sala 119. Primer piso edificio nuevo FACSO\n   Slack"
  },
  {
    "objectID": "syllabus.html#resumen",
    "href": "syllabus.html#resumen",
    "title": "Programa",
    "section": "Resumen",
    "text": "Resumen\nEste curso busca dar un primer acercamiento a la investigación social cuantitativa, abarcando desde aspectos iniciales básicos de estadística descriptiva y visualización de datos, hasta análisis e interpretación de modelos explicativos de investigación social. Asimismo, se busca que los y las estudiantes logren familiarizarse con el uso de Rstudio para el análisis de datos sociales.\nLa metodología incluye clases lectivas y trabajo práctico en R."
  },
  {
    "objectID": "syllabus.html#objetivo-general",
    "href": "syllabus.html#objetivo-general",
    "title": "Programa",
    "section": "Objetivo general",
    "text": "Objetivo general\nAl finalizar el curso, el/la estudiante podrá elaborar y analizar diseños de investigación social de carácter cuantitativo, así como describir cuantitativamente un conjunto de datos utilizando el lenguaje R."
  },
  {
    "objectID": "syllabus.html#objetivos-específicos",
    "href": "syllabus.html#objetivos-específicos",
    "title": "Programa",
    "section": "Objetivos específicos",
    "text": "Objetivos específicos\nAl concluir el curso lo/as estudiantes deberán haber alcanzado los siguientes resultados de aprendizaje:\n\nConocer las etapas de un diseño de investigación social cuantitativa y sus principales elementos\nFormular diseños de investigación social cuantitativa\nConocer y aplicar instrumentos de medición y tipos de estudios cuantitativos\nInterpretar y analizar los elementos centrales de una base de datos con información social\nAplicar e interpretar técnicas de estadística descriptiva según las distintas características de los datos\nAplicar e interpretar técnicas de estadística correlacional e inferencia estadística para variables con distinta unidad de medida\nAplicar e interpretar técnicas de regresión lineal y logística para variables numéricas y variables categóricas"
  },
  {
    "objectID": "syllabus.html#saberes-contenidos",
    "href": "syllabus.html#saberes-contenidos",
    "title": "Programa",
    "section": "Saberes / contenidos",
    "text": "Saberes / contenidos\n\nMódulo 1: Estadística descriptiva\n1.1 Elementos básicos de la investigación social\n\nEtapas de la investigación Social\nTipos de diseños\nDiseño de instrumentos de medición\nBases de datos: datos de corte transversal, series de tiempo, cohortes, panel o longitudinal\n\n1.2 Operacionalización y análisis de datos\n\nOperacionalización y niveles de medición\nTidy data: unir, dividir, filtrar y ordenar datos en R\nRecodificación de variables: descriptivos básicos, casos perdidos, etiquetamiento de variables\nAgrupación de datos y construcción de variables a partir de datos existentes\nConstrucción de índices y validez de escalas\n\n1.3 Visualización de datos en R\n\nTablas descriptivas y tablas de contingencia\nggplot2: gráficos de barra, de caja, dispersión e histograma\n\n\n\nMódulo 2: Inferencia y estadística correlacional\n2.1 Inferencia estadística\n2.2 Pruebas de hipótesis\n2.3 Correlación\n\n\nMódulo 3: Regresión lineal y regresión logística\n3.1 Regresión lineal de mínimos cuadrados\n\nAspectos centrales y supuestos de la regresión MCO\nInterpretación de coeficientes (variables cuantitativas y cualitativas) y efectos de interacción\nRepresentación gráfica de coeficientes de regresión lineal\n\n3.2 Regresión logística binaria\n\nAspectos básicos de la regresión logística\nTipos de coeficientes e interpretación\nRepresentación gráfica (cálculo de probabilidades predichas)"
  },
  {
    "objectID": "syllabus.html#bibliografía",
    "href": "syllabus.html#bibliografía",
    "title": "Programa",
    "section": "Bibliografía",
    "text": "Bibliografía\nWickham, Hadley & Grolemund, Garrett (2017). R for Data Science. Visualize, model, transform, tidy and import data. / Versión en español disponible acá\nMoore, D. S., & Comas, J. (2010). Estadística aplicada básica. Barcelona: Antoni Bosch.\nWooldridge, J. M. (2008). Introducción a la econometría: un enfoque moderno. Paraninfo Cengage Learning.\nCamarero, et al (2017) Regresión Logística: Fundamentos y aplicación a la investigación sociológica.\nHair, Joseph F., et al. (2004). Análisis multivariante. 5ta ed. Madrid: Prentice Hall.\nCharte, Francisco (2014). Análisis exploratorio y Visualización de datos con R."
  },
  {
    "objectID": "syllabus.html#metodología",
    "href": "syllabus.html#metodología",
    "title": "Programa",
    "section": "Metodología",
    "text": "Metodología\nEl curso se organiza en sesiones semanales, con una parte lectiva seguida de una práctica. En la parte lectiva se transmiten y discuten los conceptos centrales de la investigación cuantitativa. En la parte práctica se aplicarán los conceptos transmitidos en la parte lectiva, además de resolver dudas en el avance de los trabajos de investigación"
  },
  {
    "objectID": "syllabus.html#evaluación",
    "href": "syllabus.html#evaluación",
    "title": "Programa",
    "section": "Evaluación",
    "text": "Evaluación\nLa evaluación consistirá en"
  },
  {
    "objectID": "syllabus.html#requisitos-de-aprobación",
    "href": "syllabus.html#requisitos-de-aprobación",
    "title": "Programa",
    "section": "Requisitos de aprobación",
    "text": "Requisitos de aprobación\n\nNota mínima de aprobación: 4,0 (en escala de 1 a 7)."
  },
  {
    "objectID": "syllabus.html#palabras-clave",
    "href": "syllabus.html#palabras-clave",
    "title": "Programa",
    "section": "Palabras Clave",
    "text": "Palabras Clave\n\nEstadística, investigación cuantitativa, manipulación de datos, visualización de datos, interpretación de coeficientes"
  },
  {
    "objectID": "trabajos.html",
    "href": "trabajos.html",
    "title": "Trabajos",
    "section": "",
    "text": "La evaluación consistirá en la elaboración de reportes de investigación enfocados en reproducibilidad de la investigación social. La reproducibilidad es entendida como la posiblidad de regenerar de manera independiente los resultados de una investigación usando los mismos materiales originales de una investigación ya publicada (más información en lisa-coes.com)\nLos reportes serán elaborados en parejas. Cada pareja deberá elegir una de las siguientes investigaciones propuestas y seguir las instrucciones según cada evaluación:\n\n\n\nDisi Pavlic, Rodolfo (2018). Sentenced to Debt: Explaining Student Mobilization in Chile. Latin American Research Review 53(3), pp. 448-465, DOI: https://doi.org/10.25222/larr.395 : Análisis de las movilizaciones estudiantiles en Chile utilizando la Encuesta Nacional de Juventud del 2012 (paper en inglés)\nOrtiz-Inostroza, C., & Lopez, E. (2017). Explorando modelos estadísticos para explicar la participación en protestas en Chile. Revista de Sociología 32(1), 13-31. DOI: 10.5354/0719-529x.2017.47883 : Estudio de los factores individuales que influyen en la participación en protestas en Chile, con datos del informe de Desarrollo Humano de 2015 del PNUD.\nCereceda-Marambio, K., & Torres-Solís, A. (2017). Satisfacción con la democracia en Chile: De lo normativo a lo valorativo. Revista de Sociología 32(1), 32-49. doi: 10.5354/0719-529x.2017.47884 : estudio que intenta explicar y predecir la satisfacción con la democracia en Chile con datos del Latinobarómetro del 2015\nSepúlveda-Rodríguez, I., & Garrido-Vergara, L. (2022). Satisfacción con la democracia y legitimidad en Chile. Revista de Sociología, 37(2), 1–15. https://doi.org/10.5354/0719-529X.2022.69099 : Estudio que analiza los factores que influyen en la satisfacción en la democracia en Chile, con especial interés en la legitimidad y confianza en el régimen político. Utiliza datos del latinobarómetro del 2020\nOrtiz, Iván (2016). ACTITUDES DE LOS ESTUDIANTES EN ESCUELAS SEGREGADAS Y EN ESCUELAS INCLUSIVAS, HACIA LA TOLERANCIA SOCIAL Y LA CONVIVENCIA ENTRE PARES. CALIDAD EN LA EDUCACIÓN no 44, pp. 68-97 : Estudio que analiza actitudes tolerantes de los estudiantes, diferenciando por contexto escolar. Utiliza datos del International Civic and Citizenship Education Study (ICCS) del 2009.\n\n\n\n\nEs posible utilizar un estudio distinto a los propuestos y que se acerque a sus temas de interés, pero se deben guiar por estos criterios básicos y confirmar la elección con alguno de los profesores:\n\nDebe ser un estudio de carácter cuantitativo\nLa base de datos debe estar disponible online (gratis)\nDebe ser posible identificar los tres temas básicos del curso: 1) descripción y visualización de datos, 2) análisis bivariado y contraste de hipótesis y 3) explicación de modelos causales (regresión lineal y/o logística). Se deben evitar estudios que posean estrategias de análisis más complejas."
  },
  {
    "objectID": "trabajos.html#reporte-1",
    "href": "trabajos.html#reporte-1",
    "title": "Trabajos",
    "section": "Reporte 1",
    "text": "Reporte 1\n\nSeleccionar una de las investigaciones propuestas\nDescargar la base de datos utilizada en la investigación\nOperacionalización: Manipulación de datos para obtener las mismas variables utilizadas en la investigación. Se espera que l-s estudiantes sean capaces de seleccionar las variables utilizadas en la investigación escogida, agruparlas, reordenarlas y asignarles los nombres y etiquetas según corresponda.\nVisualización de datos: Elaboración de tablas y/o gráficos, en el contexto de un reporte científico de investigación, que intente reproducir o profundizar los principales hallazgos de la investigación. Para esta primera entrega se espera que sean capaces de reproducir la tabla descriptiva que muestre las medidas de tendencia central de las variables utilizadas en la investigación, así como su contraparte de tablas de frecuencias en el caso de variables categóricas. También se espera que sean capaces de elaborar uno o dos gráficos univariados que permitan visualizar la distribución de las principales variables de interés.\nSi la investigación escogida no posee tablas o gráficos descriptivos, deberán elaborar de igual forma una tabla y uno o dos gráficos que permitan visualizar la operacionalización de las variables.\nNo es necesario elaborar un informe teórico sobre el tema de investigación. En la introducción del reporte deben mencionar la investigación que están reproduciendo y la fuente de datos utilizada. El objetivo del trabajo es que sean capaces de operacionalizar variables, escoger la mejor forma de visualizar sus medidas de tendencia central y/o frecuencias e interpretar estas tablas/gráficos.\n\nEntrega:\n\nViernes 21 de Abril a través de UCursos, sección tareas\nFormato Tradicional: archivo .pdf en tamaño carta o A4, letra Times New Roman, tamaño 12, interlineado 1,5, márgenes normales (2,5 cm superior e inferior, 3 cm derecho e izquierdo). Se considerará positivamente la entrega de reportes elaborados en RMarkdown\nNo más de 10 páginas\nincluir referencias de la literatura / bases de datos revisadas\natrasos, 0,5 por día de atraso.\n\nRúbrica de evaluación:\n\n\n\n\n\n\n\n\nÍtem\nObjetivo\nPuntaje\n\n\n\n\n1. Cargar base de datos\nL-s estudiantes son capaces de descargar la base de datos utilizada en la investigación y posteriormente cargarla en R\n2pts\n\n\n2. Selección de variables\nL-s estudiantes son capaces de seleccionar las variables utilizadas en la investigaciónn escogida\n2pts\n\n\n3. Operacionalización de variables\nL-s estudiantes son capaces de operacionalizar correctamente las variables de interés, obteniendo resultados similares a los de la investigación escogida. Las variables deben tener una correcta escala de medición (1pto), correcto paso a NA (1pto), correcto orden de medición (1pto) y etiquetas correctas (1pto)\n4pts\n\n\n4. Visualización de resultados\nL-s estudiantes son capaces de visualizar correctamente las variables de interés. Se espera que el reporte incluya una tabla descriptiva (2ptos) y uno o dos gráficos (2ptos)\n4ptos\n\n\n5. Interpretación de resultados\nL-s estudiantes son capaces de interpretar correctamente las tablas y gráficos presentados\n2pts\n\n\nTotal\n-\n14ptos"
  },
  {
    "objectID": "trabajos.html#reporte-2",
    "href": "trabajos.html#reporte-2",
    "title": "Trabajos",
    "section": "Reporte 2",
    "text": "Reporte 2"
  },
  {
    "objectID": "trabajos.html#reporte-3",
    "href": "trabajos.html#reporte-3",
    "title": "Trabajos",
    "section": "Reporte 3",
    "text": "Reporte 3"
  },
  {
    "objectID": "trabajos.html#requisitos-de-aprobación",
    "href": "trabajos.html#requisitos-de-aprobación",
    "title": "Trabajos",
    "section": "Requisitos de aprobación",
    "text": "Requisitos de aprobación\n\nNota mínima de aprobación: 4,0 (en escala de 1 a 7)."
  }
]